<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="" description="">
	<nodes>
		<node id="0" name="Datasets" qualified_name="Orange.widgets.data.owdatasets.OWDataSets" project_name="Orange3" version="" title="Datasets" position="(150, 150)" />
		<node id="1" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score CV" position="(449.0, 166.0)" />
		<node id="2" name="Tree" qualified_name="Orange.widgets.model.owtree.OWTreeLearner" project_name="Orange3" version="" title="Tree, max. depth=1" position="(211.0, 284.0)" />
		<node id="3" name="Tree" qualified_name="Orange.widgets.model.owtree.OWTreeLearner" project_name="Orange3" version="" title="Tree, max. depth=2" position="(211.0, 404.0)" />
		<node id="4" name="Tree" qualified_name="Orange.widgets.model.owtree.OWTreeLearner" project_name="Orange3" version="" title="Tree, max. depth=3" position="(211.0, 524.0)" />
		<node id="5" name="Tree" qualified_name="Orange.widgets.model.owtree.OWTreeLearner" project_name="Orange3" version="" title="Tree, max. depth=4" position="(211.0, 644.0)" />
		<node id="6" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score Traindata" position="(449.0, 286.0)" />
		<node id="7" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Validation_curve.py (1)" position="(676.0, 167.0)" />
	</nodes>
	<links>
		<link id="0" source_node_id="0" sink_node_id="1" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="1" source_node_id="2" sink_node_id="1" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="2" source_node_id="3" sink_node_id="1" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="3" source_node_id="4" sink_node_id="1" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="4" source_node_id="5" sink_node_id="1" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="5" source_node_id="0" sink_node_id="6" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="6" source_node_id="2" sink_node_id="6" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="7" source_node_id="3" sink_node_id="6" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="8" source_node_id="4" sink_node_id="6" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="9" source_node_id="5" sink_node_id="6" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="10" source_node_id="1" sink_node_id="7" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="11" source_node_id="6" sink_node_id="7" source_channel="Predictions" sink_channel="Object" enabled="true" />
	</links>
	<annotations>
		<text id="0" type="text/markdown" rect="(115.0, 17.0, 538.0, 82.0)" font-family="MS Shell Dlg 2" font-size="16"># Example for Validation curve
(Regression)</text>
		<text id="1" type="text/plain" rect="(615.0, 281.0, 190.0, 63.0)" font-family="MS Shell Dlg 2" font-size="16">possible Performance metrics: R2 and MSE
see settings</text>
		<arrow id="2" start="(611.0, 287.0)" end="(637.0, 227.0)" fill="#C1272D" />
	</annotations>
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'controlAreaVisible': True, 'header_state': b"\x00\x00\x00\xff\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x04-\x00\x00\x00\x07\x01\x01\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00d\xff\xff\xff\xff\x00\x00\x00\x81\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00'\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01\x03\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01s\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x03\xe8\x00\x00\x00\x00d", 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd', 'selected_id': 'core\\housing.tab', 'splitter_state': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01,\x00\x00\x00\xc8\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', '__version__': 1}</properties>
		<properties node_id="1" format="pickle">gASV/QcAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li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</properties>
		<properties node_id="2" format="literal">{'auto_apply': True, 'binary_trees': True, 'controlAreaVisible': True, 'learner_name': '', 'limit_depth': True, 'limit_majority': False, 'limit_min_internal': False, 'limit_min_leaf': False, 'max_depth': 1, 'min_internal': 5, 'min_leaf': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e', 'sufficient_majority': 95, '__version__': 1}</properties>
		<properties node_id="3" format="literal">{'auto_apply': True, 'binary_trees': True, 'controlAreaVisible': True, 'learner_name': '', 'limit_depth': True, 'limit_majority': False, 'limit_min_internal': False, 'limit_min_leaf': False, 'max_depth': 2, 'min_internal': 5, 'min_leaf': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\xce\x00\x00\x01c\x00\x00\x01\xfe\x00\x00\x02\x9f\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e', 'sufficient_majority': 95, '__version__': 1}</properties>
		<properties node_id="4" format="literal">{'auto_apply': True, 'binary_trees': True, 'controlAreaVisible': True, 'learner_name': '', 'limit_depth': True, 'limit_majority': False, 'limit_min_internal': False, 'limit_min_leaf': False, 'max_depth': 3, 'min_internal': 5, 'min_leaf': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\xce\x00\x00\x01c\x00\x00\x01\xfe\x00\x00\x02\x9f\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e', 'sufficient_majority': 95, '__version__': 1}</properties>
		<properties node_id="5" format="literal">{'auto_apply': True, 'binary_trees': True, 'controlAreaVisible': True, 'learner_name': '', 'limit_depth': True, 'limit_majority': False, 'limit_min_internal': False, 'limit_min_leaf': False, 'max_depth': 3, 'min_internal': 5, 'min_leaf': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\xce\x00\x00\x01c\x00\x00\x01\xfe\x00\x00\x02\x9f\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\xcf\x00\x00\x01\x82\x00\x00\x01\xfd\x00\x00\x02\x9e', 'sufficient_majority': 95, '__version__': 1}</properties>
		<properties node_id="6" format="pickle">gASV/QcAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li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</properties>
		<properties node_id="7" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x0e\x00\x00\x008\x00\x00\x03\x9f\x00\x00\x03&gt;\x00\x00\x00\x0f\x00\x00\x00W\x00\x00\x03\x9e\x00\x00\x03=\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\x0f\x00\x00\x00W\x00\x00\x03\x9e\x00\x00\x03=', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Plot Validation Curve\n#######################\n# Settings:\nscore = "MSE"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: Predictions from Test &amp; Score with Cross validation\n  and optional: Predictions from Test &amp; Score with test on training data\n* Widget output: -\n\n* Computes and shows validation curve for learners out of cross validation by widget Test &amp; Score\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or MSE for regression.\n* Uses names of learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nn = len(data)\ny_true = data.Y\nn_meta_cols = len(data.domain.metas)\n\nif data.domain.class_var.is_continuous:\n    problem = "reg"\n    n_classes = 0\n    n_learner = n_meta_cols-1\nelse:\n    problem = "class"\n    n_classes = len(data.domain.class_var.values)\n    n_learner = int((n_meta_cols-1)/(n_classes+1))\n\nif in_object == None:\n    show_traindata = False\nelse:\n    show_traindata = True\n    traindata = in_object.copy()\n\nfolds = data.metas[:, n_learner*(n_classes+1)]  # column with folds-indicator\nk = len(np.unique(folds))  # number of folds\n\nca = np.zeros([n_learner,k])\nmse= np.zeros([n_learner,k])\nr2 = np.zeros([n_learner,k])\nr2_total = np.zeros([n_learner])\nca_train = np.zeros([n_learner,k])\nmse_train = np.zeros([n_learner,k])\nr2_train = np.zeros([n_learner,k])\n\n# Split data in folds and calculate metrics\n# -----------------------------------------\nif problem == "class":\n    for fold in range(k):\n        y_test = y_true[folds==fold].astype(int)\n        y_pred_test = data.metas[:,0:n_learner][folds==fold].astype(int)\n        for learner in range(n_learner):  # calculate metrics\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[:, learner])\n\nelif problem == "reg":\n    for fold in range(k):\n        y_test = y_true[folds==fold]\n        y_pred_test = data.metas[:,0:n_learner][folds==fold]\n        for learner in range(n_learner):\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[:, learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[:, learner])\n            r2_total[learner] = metrics.r2_score(y_true, data.metas[:, learner])\n\nif show_traindata: \n    if problem == "class":\n        y_train = traindata.Y.astype(int)\n        y_pred_train = traindata.metas[:,0:n_learner].astype(int)\n        for learner in range(n_learner):\n            ca_train[learner] = metrics.accuracy_score(y_train, y_pred_train[:, learner])\n    elif problem == "reg":\n        y_train = traindata.Y\n        y_pred_train = traindata.metas[:,0:n_learner]\n        for learner in range(n_learner):\n            mse_train[learner] = metrics.mean_squared_error(y_train, y_pred_train[:, learner])\n            r2_train[learner] = metrics.r2_score(y_train, y_pred_train[:, learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\n#result_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nresult_table["Models"] = [F"{data.domain.metas[learner]}" for learner in range(n_learner)]\n#print(result_table["Models"])\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner in range(n_learner)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner in range(n_learner)]\n    if show_traindata: result_table["CA_train"] = [ca_train[learner].mean() for learner in range(n_learner)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner in range(n_learner)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner in range(n_learner)]\n    result_table["R2"] = [r2[learner].mean() for learner in range(n_learner)]\n    result_table["R2"] = r2_total\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner in range(n_learner)]\n    if show_traindata:\n        result_table["MSE_train"] = [mse_train[learner].mean() for learner in range(n_learner)]\n        result_table["R2_train"] = [r2_train[learner].mean() for learner in range(n_learner)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    if show_traindata: print(result_table[["Models", "MSE_train", "R2_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    if show_traindata: plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        if show_traindata: plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        if show_traindata: plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}], 'scriptText': '# Plot Validation Curve\n#######################\n# Settings:\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: Predictions from Test &amp; Score with Cross validation\n  and optional: Predictions from Test &amp; Score with test on training data\n* Widget output: -\n\n* Computes and shows validation curve for learners out of cross validation by widget Test &amp; Score\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or MSE for regression.\n* Uses names of learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nn = len(data)\ny_true = data.Y\nn_meta_cols = len(data.domain.metas)\n\nif data.domain.class_var.is_continuous:\n    problem = "reg"\n    n_classes = 0\n    n_learner = n_meta_cols-1\nelse:\n    problem = "class"\n    n_classes = len(data.domain.class_var.values)\n    n_learner = int((n_meta_cols-1)/(n_classes+1))\n\nif in_object == None:\n    show_traindata = False\nelse:\n    show_traindata = True\n    traindata = in_object.copy()\n\nfolds = data.metas[:, n_learner*(n_classes+1)]  # column with folds-indicator\nk = len(np.unique(folds))  # number of folds\n\nca = np.zeros([n_learner,k])\nmse= np.zeros([n_learner,k])\nr2 = np.zeros([n_learner,k])\nr2_total = np.zeros([n_learner])\nca_train = np.zeros([n_learner,k])\nmse_train = np.zeros([n_learner,k])\nr2_train = np.zeros([n_learner,k])\n\n# Split data in folds and calculate metrics\n# -----------------------------------------\nif problem == "class":\n    for fold in range(k):\n        y_test = y_true[folds==fold].astype(int)\n        y_pred_test = data.metas[:,0:n_learner][folds==fold].astype(int)\n        for learner in range(n_learner):  # calculate metrics\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[:, learner])\n\nelif problem == "reg":\n    for fold in range(k):\n        y_test = y_true[folds==fold]\n        y_pred_test = data.metas[:,0:n_learner][folds==fold]\n        for learner in range(n_learner):\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[:, learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[:, learner])\n            r2_total[learner] = metrics.r2_score(y_true, data.metas[:, learner])\n\nif show_traindata: \n    if problem == "class":\n        y_train = traindata.Y.astype(int)\n        y_pred_train = traindata.metas[:,0:n_learner].astype(int)\n        for learner in range(n_learner):\n            ca_train[learner] = metrics.accuracy_score(y_train, y_pred_train[:, learner])\n    elif problem == "reg":\n        y_train = traindata.Y\n        y_pred_train = traindata.metas[:,0:n_learner]\n        for learner in range(n_learner):\n            mse_train[learner] = metrics.mean_squared_error(y_train, y_pred_train[:, learner])\n            r2_train[learner] = metrics.r2_score(y_train, y_pred_train[:, learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\n#result_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nresult_table["Models"] = [F"{data.domain.metas[learner]}" for learner in range(n_learner)]\n#print(result_table["Models"])\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner in range(n_learner)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner in range(n_learner)]\n    if show_traindata: result_table["CA_train"] = [ca_train[learner].mean() for learner in range(n_learner)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner in range(n_learner)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner in range(n_learner)]\n    result_table["R2"] = [r2[learner].mean() for learner in range(n_learner)]\n    result_table["R2"] = r2_total\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner in range(n_learner)]\n    if show_traindata:\n        result_table["MSE_train"] = [mse_train[learner].mean() for learner in range(n_learner)]\n        result_table["R2_train"] = [r2_train[learner].mean() for learner in range(n_learner)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    if show_traindata: print(result_table[["Models", "MSE_train", "R2_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    if show_traindata: plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        if show_traindata: plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        if show_traindata: plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\x9c\x00\x00\x01#\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
