<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="Beispiel Validation curve fÃ¼r Klassifikation" description="">
	<nodes>
		<node id="0" name="Tree" qualified_name="Orange.widgets.model.owtree.OWTreeLearner" project_name="Orange3" version="" title="Tree" position="(450.0, -129.0)" />
		<node id="1" name="Select Columns" qualified_name="Orange.widgets.data.owselectcolumns.OWSelectAttributes" project_name="Orange3" version="" title="Select Columns" position="(331.0, -199.0)" />
		<node id="2" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table" position="(456.0, -333.0)" />
		<node id="3" name="Scatter Plot" qualified_name="Orange.widgets.visualize.owscatterplot.OWScatterPlot" project_name="Orange3" version="" title="Scatter Plot" position="(743.0, -339.0)" />
		<node id="4" name="Paint Data" qualified_name="Orange.widgets.data.owpaintdata.OWPaintData" project_name="Orange3" version="" title="Paint Data" position="(166.0, -199.0)" />
		<node id="5" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score" position="(453.0, -7.0)" />
		<node id="6" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions2D.py" position="(744.0, 1.0)" />
		<node id="7" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Learning_curve.py" position="(744.0, -192.0)" />
	</nodes>
	<links>
		<link id="0" source_node_id="1" sink_node_id="2" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="1" source_node_id="4" sink_node_id="1" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="2" source_node_id="1" sink_node_id="5" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="3" source_node_id="0" sink_node_id="5" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="4" source_node_id="5" sink_node_id="6" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="5" source_node_id="1" sink_node_id="0" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="6" source_node_id="0" sink_node_id="6" source_channel="Model" sink_channel="Classifier" enabled="true" />
		<link id="7" source_node_id="1" sink_node_id="3" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="8" source_node_id="1" sink_node_id="7" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="9" source_node_id="0" sink_node_id="7" source_channel="Learner" sink_channel="Learner" enabled="true" />
	</links>
	<annotations>
		<text id="0" type="text/markdown" rect="(128.0, -503.0, 719.0, 97.0)" font-family="MS Shell Dlg 2" font-size="16"># Example for a Learning Curve
(Variation of the amount of training data)</text>
		<text id="1" type="text/plain" rect="(846.0, -358.0, 150.0, 31.0)" font-family="MS Shell Dlg 2" font-size="16">see the data</text>
		<text id="2" type="text/plain" rect="(860.0, -223.0, 242.0, 81.0)" font-family="MS Shell Dlg 2" font-size="16">see the learning curve 
(no replicable training; so several runs give different results)</text>
		<text id="3" type="text/plain" rect="(875.0, -24.0, 150.0, 50.0)" font-family="MS Shell Dlg 2" font-size="16">some overfitting occurs 
(reduce with "Do not split subsets smaller than" in Tree Widget)</text>
		<arrow id="4" start="(834.0, -341.0)" end="(782.0, -339.0)" fill="#C1272D" />
		<arrow id="5" start="(855.0, -186.0)" end="(787.0, -185.0)" fill="#C1272D" />
		<arrow id="6" start="(863.0, 0.0)" end="(789.0, 2.0)" fill="#C1272D" />
	</annotations>
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'auto_apply': True, 'binary_trees': True, 'controlAreaVisible': True, 'learner_name': '3', 'limit_depth': True, 'limit_majority': False, 'limit_min_internal': False, 'limit_min_leaf': False, 'max_depth': 5, 'min_internal': 10, 'min_leaf': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\xaf\x00\x00\x01\x91\x00\x00\x01\xdf\x00\x00\x02\xcd\x00\x00\x00\xb0\x00\x00\x01\xb0\x00\x00\x01\xde\x00\x00\x02\xcc\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\xb0\x00\x00\x01\xb0\x00\x00\x01\xde\x00\x00\x02\xcc', 'sufficient_majority': 95, '__version__': 1}</properties>
		<properties node_id="1" format="pickle">gASVgwEAAAAAAAB9lCiMC2F1dG9fY29tbWl0lIiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNpZ25v
cmVfbmV3X2ZlYXR1cmVzlImME3NhdmVkV2lkZ2V0R2VvbWV0cnmUQ0IB2dDLAAMAAAAAAJcAAADK
AAADhQAAAsgAAACYAAAA6QAAA4QAAALHAAAAAAAAAAAHgAAAAJgAAADpAAADhAAAAseUjBJ1c2Vf
aW5wdXRfZmVhdHVyZXOUiYwLX192ZXJzaW9uX1+USwGMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9y
YW5nZXdpZGdldC5zZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMEWRvbWFp
bl9yb2xlX2hpbnRzlH2UKIwBeJRLAoaUjAlhdHRyaWJ1dGWUSwCGlIwBeZRLAoaUjAVjbGFzc5RL
AIaUdUr+////hpRoB0sBdYwKYXR0cmlidXRlc5R9lChoE0sCaBdLAnWMBW1ldGFzlH2UdWJhdS4=
</properties>
		<properties node_id="2" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': False, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x00F\x00\x00\x06\x82\x00\x00\x04\x0f\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="3" format="pickle">gASViQIAAAAAAAB9lCiMC2F1dG9fY29tbWl0lIiMC2F1dG9fc2FtcGxllIiMEmNvbnRyb2xBcmVh
VmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21ldHJ5lENCAdnQywADAAAAAAIuAAAAuAAABpsAAAOb
AAACLwAAANcAAAaaAAADmgAAAAAAAAAAB4AAAAIvAAAA1wAABpoAAAOalIwJc2VsZWN0aW9ulE6M
EXRvb2x0aXBfc2hvd3NfYWxslIiMD3Zpc3VhbF9zZXR0aW5nc5R9lIwFZ3JhcGiUfZQojAthbHBo
YV92YWx1ZZRLgIwNY2xhc3NfZGVuc2l0eZSJjBFqaXR0ZXJfY29udGludW91c5SJjAtqaXR0ZXJf
c2l6ZZRLAIwTbGFiZWxfb25seV9zZWxlY3RlZJSJjBZvcnRob25vcm1hbF9yZWdyZXNzaW9ulImM
C3BvaW50X3dpZHRolEsKjAlzaG93X2dyaWSUiYwLc2hvd19sZWdlbmSUiIwNc2hvd19yZWdfbGlu
ZZSJdYwLX192ZXJzaW9uX1+USwWMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9yYW5nZXdpZGdldC5z
ZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMCmF0dHJfY29sb3KUTkr+////
hpSMCmF0dHJfbGFiZWyUTkr+////hpSMCmF0dHJfc2hhcGWUTkr+////hpSMCWF0dHJfc2l6ZZRO
Sv7///+GlIwGYXR0cl94lIwBeJRLZoaUjAZhdHRyX3mUjAF5lEtmhpRoCn2UaBZLBXWMCmF0dHJp
YnV0ZXOUfZQoaClLAmgsSwJ1jAVtZXRhc5R9lHViYXUu
</properties>
		<properties node_id="4" format="literal">{'attr1': 'x', 'attr2': 'y', 'autocommit': True, 'brushRadius': 75, 'controlAreaVisible': True, 'data': [[0.0849939737457802, 0.9940592933720235, 0.0], [0.08433305885729973, 0.9421865616725884, 0.0], [0.01465883386412608, 0.9475441201926051, 0.0], [0.10537249055435507, 0.9474552844427435, 0.0], [0.05164022918841678, 0.923529728394477, 0.0], [0.08689163219445477, 0.8444066896923215, 0.0], [0.08154419842016067, 0.8299954141257604, 0.0], [0.18638843023003582, 0.7263865719056899, 0.0], [0.1515934264244102, 0.7321731024977043, 0.0], [0.17568340204048707, 0.6246882139079721, 0.0], [0.2576230037791837, 0.6020232042583871, 0.0], [0.3041952170718347, 0.5025793014543406, 0.0], [0.2998195539591507, 0.42121837418121505, 0.0], [0.3137386715375554, 0.41005021978226325, 0.0], [0.43181974090897374, 0.342975543883996, 0.0], [0.40199055447353543, 0.29702536094275145, 0.0], [0.45398120092044003, 0.1728278763619906, 0.0], [0.5087576369440221, 0.10334586452048426, 0.0], [0.5494462506642767, 0.20705977286905278, 0.0], [0.5856574607706884, 0.08894979517301954, 0.0], [0.6219610725130967, 0.09823086065650886, 0.0], [0.614335003121101, 0.06195878888840818, 0.0], [0.681354062885248, 0.04233934976328631, 0.0], [0.7084765157203051, 0.0109477746760318, 0.0], [0.6671913001084389, 0.07833241549482622, 0.0], [0.7060391529776427, 0.01190023693139447, 0.0], [0.7549112802704925, 0.09342864155490296, 0.0], [0.7371728322132147, 0.193708506767168, 0.0], [0.7242367003353927, 0.19627596088728522, 0.0], [0.7130917414084075, 0.26732679049226676, 0.0], [0.7632527085948293, 0.2238336263812798, 0.0], [0.7897575711938213, 0.30262310205166343, 0.0], [0.8309424549588044, 0.24430570488713976, 0.0], [0.8886680532573822, 0.31817095654180577, 0.0], [0.8304050708582407, 0.35544296309534057, 0.0], [0.962115946298827, 0.4635824816084444, 0.0], [0.9587430723470388, 0.4565850961775765, 0.0], [0.12619684627719852, 0.980133322498237, 0.0], [0.12553593138871805, 0.9344499111871516, 0.0], [0.05586170639554441, 0.9382601396100808, 0.0], [0.14886441155974106, 0.9335293135689571, 0.0], [0.09169857748285126, 0.9173404080061275, 0.0], [0.11321568964508313, 0.8645219809544574, 0.0], [0.09184491655301527, 0.8841519675238186, 0.0], [0.17723223633416507, 0.8083950670513209, 0.0], [0.12526936897378185, 0.8435808694879956, 0.0], [0.12875790832414957, 0.7685899129370983, 0.0], [0.1878070253231693, 0.773776845035086, 0.0], [0.21377780235011118, 0.7052795441727872, 0.0], [0.1716328394169604, 0.67807517029772, 0.0], [0.135192890568076, 0.7133269188113895, 0.0], [0.22923895096283364, 0.6663675341752582, 0.0], [0.173085707076767, 0.6482692929815865, 0.0], [0.1998968203100271, 0.5565657404396606, 0.0], [0.21118133532822314, 0.5257669810253387, 0.0], [0.2106670765170594, 0.6573328311214801, 0.0], [0.22398780188379422, 0.5392228534254467, 0.0], [0.2534242682042995, 0.5454092587147614, 0.0], [0.22634128678357843, 0.5137791772379228, 0.0], [0.23399801804096196, 0.44914740877198933, 0.0], [0.26932533757106475, 0.49570706820988836, 0.0], [0.3033149358280249, 0.45812617273428435, 0.0], [0.273474962585997, 0.5146795028734671, 0.0], [0.290576854952508, 0.3801648000381906, 0.0], [0.3405935064823416, 0.4291992726228641, 0.0], [0.3125543402922093, 0.49389054560211954, 0.0], [0.28588391757058107, 0.4500380968096153, 0.0], [0.27130538593264436, 0.4576483924340144, 0.0], [0.3214663531190663, 0.3630933351191439, 0.0], [0.3388150218221874, 0.3970102379739936, 0.0], [0.3445196542406713, 0.2938202679939359, 0.0], [0.36790952542973393, 0.3228129468330679, 0.0], [0.2970567764237701, 0.3198543708623309, 0.0], [0.40702169136166344, 0.37383733597737645, 0.0], [0.3853364296181338, 0.33279868841058613, 0.0], [0.43207242230707077, 0.286111029636963, 0.0], [0.4526500654134333, 0.3003308739979547, 0.0], [0.3909198338859974, 0.27183541843284165, 0.0], [0.4172854512601999, 0.2665713650796615, 0.0], [0.45293108953504874, 0.2481706712303525, 0.0], [0.4519684756564404, 0.2053615579212107, 0.0], [0.4267576931657414, 0.26713038996795546, 0.0], [0.471918138362469, 0.20277177254121356, 0.0], [0.5100297919305125, 0.21287493735389992, 0.0], [0.4711754076749277, 0.1986559544425043, 0.0], [0.47944887936264724, 0.09742829503719891, 0.0], [0.49247040350800675, 0.08950310575418721, 0.0], [0.48223185876098784, 0.10519756317070687, 0.0], [0.5367183392579542, 0.10282737458036945, 0.0], [0.573959697703462, 0.04330778305178833, 0.0], [0.5759335770311356, 0.11761885535631426, 0.0], [0.5227907505779137, 0.016307198010949132, 0.0], [0.5553937456787837, 0.03910179186023508, 0.0], [0.5876727615290664, 0.06053887992251487, 0.0], [0.621669924709904, 0.030752470182844053, 0.0], [0.5639862485581109, 0.059397355081101486, 0.0], [0.5920179683649222, 0.016289787746709992, 0.0], [0.6104032974269201, 0.05475328202842035, 0.0], [0.627266701361008, 0.018492411129360283, 0.0], [0.6390791442991757, 0.1310408886242428, 0.0], [0.7754317691080824, 0.05367331653867463, 0.0], [0.7200750915741762, 0.1432809038229935, 0.0], [0.8135792549899328, 0.13838549789875998, 0.0], [0.8085359182306997, 0.19377492910526808, 0.0], [0.7365210950434238, 0.20514958472358596, 0.0], [0.8131376203248176, 0.18585018573143847, 0.0], [0.8130075554145532, 0.219790809668767, 0.0], [0.7695256314363, 0.1776366773753771, 0.0], [0.8056303754250222, 0.21085147266235793, 0.0], [0.827905175240999, 0.3363668225860167, 0.0], [0.8405328842045049, 0.2511429510820869, 0.0], [0.8037033647694339, 0.2978121905630766, 0.0], [0.881594333263269, 0.29279031445868, 0.0], [0.8684840069079501, 0.3586241778034457, 0.0], [0.8692221520489755, 0.3316737931568695, 0.0], [0.7460045873090934, 0.3580814297759812, 0.0], [0.9461906251414608, 0.37414079036064757, 0.0], [0.8331060710985767, 0.3370037415385112, 0.0], [0.9213493452200479, 0.3463642632052089, 0.0], [0.9285413337649873, 0.36134358130268174, 0.0], [0.8986237883864182, 0.39546381766507926, 0.0], [0.9147692449488956, 0.5096330126960861, 0.0], [0.8937882981060512, 0.40704802331276274, 0.0], [0.9369802400212208, 0.45002134748557965, 0.0], [0.9361805132907901, 0.5434158871142304, 0.0], [0.8778136697854534, 0.4760915665189867, 0.0], [0.9409219653823817, 0.4784702794520927, 0.0], [0.9346223469336897, 0.45499133690922583, 0.0], [0.9739997763244664, 0.515571091373099, 0.0], [0.9978211472873165, 0.5672567546495864, 0.0], [0.9461753422093317, 0.48991855276178753, 0.0]], 'density': 1, 'hasAttr2': True, 'labels': ['C1', 'C2'], 'savedWidgetGeometry': b"\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x03\x00\x00\x00,\x00\x00\x04p\x00\x00\x03(\x00\x00\x00\x04\x00\x00\x00K\x00\x00\x04o\x00\x00\x03'\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\x04\x00\x00\x00K\x00\x00\x04o\x00\x00\x03'", 'symbol_size': 10, 'table_name': 'Painted data', '__version__': 1}</properties>
		<properties node_id="5" format="pickle">gASVlAIAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSJjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAC/wAAAPoAAAZAAAADZgAAAv8AAAD6AAAGQAAAA2YAAAAAAAAAAAeAAAAC
/wAAAPoAAAZAAAADZpSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwOVHJhaW4gdGltZSBbc12UjANNQUWUjAJSMpSMAkNB
lIwCRjGUjA1UZXN0IHRpbWUgW3NdlIwDTVNFlIwJUHJlY2lzaW9ulIwDQVVDlIwGUmVjYWxslIwE
Uk1TRZSQc4wLX192ZXJzaW9uX1+USwOMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9yYW5nZXdpZGdl
dC5zZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMD2NsYXNzX3NlbGVjdGlv
bpSMFihBdmVyYWdlIG92ZXIgY2xhc3NlcymUSv////+GlIwMZm9sZF9mZWF0dXJllE5K/v///4aU
jBVmb2xkX2ZlYXR1cmVfc2VsZWN0ZWSUiUr+////hpRoDX2UaBxLA3WMCmF0dHJpYnV0ZXOUjAF4
lEsChpSFlIwFbWV0YXOUKYwKY2xhc3NfdmFyc5SMAXmUSwKGlIWUdWJhdS4=
</properties>
		<properties node_id="6" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb9\x00\x00\x02\x02\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb9\x00\x00\x02\x02\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb9\x00\x00\x02\x02', 'scriptLibrary': [{'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 2         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}], 'scriptText': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\xcc\x00\x00\x00\x87\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="7" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02v\x00\x00\x02\\\x00\x00\x06\xb0\x00\x00\x04\xf3\x00\x00\x02w\x00\x00\x02{\x00\x00\x06\xaf\x00\x00\x04\xf2\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02w\x00\x00\x02{\x00\x00\x06\xaf\x00\x00\x04\xf2', 'scriptLibrary': [{'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#############################################################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with type of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nX_train, X_test, y_train, y_test = train_test_split(data.X, data.Y, test_size=0.2)\ntrainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\ntestset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\nn = len(trainset)\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, trainset, testset):\n    \n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test, squared=False))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "-o", linewidth=2, label="Training score", color="darkorange")\n    plt.plot(train_sizes, val_errors, "-", linewidth=3, label="Test score", color="navy")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, trainset, testset)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}], 'scriptText': '# Plot Learning Curve\n#############################################################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with type of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nX_train, X_test, y_train, y_test = train_test_split(data.X, data.Y, test_size=0.2)\ntrainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\ntestset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\nn = len(trainset)\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, trainset, testset):\n    \n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test, squared=False))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "-o", linewidth=2, label="Training score", color="darkorange")\n    plt.plot(train_sizes, val_errors, "-", linewidth=3, label="Test score", color="navy")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, trainset, testset)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01\x1a\x00\x00\x016\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
