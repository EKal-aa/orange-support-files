<?xml version='1.0' encoding='utf-8'?>
<scheme description="" title="" version="2.0">
	<nodes>
		<node id="0" name="Datasets" position="(150, 150)" project_name="Orange3" qualified_name="Orange.widgets.data.owdatasets.OWDataSets" title=" Datasets (iris)" version="" />
		<node id="1" name="Edit Domain" position="(300, 150)" project_name="Orange3" qualified_name="Orange.widgets.data.oweditdomain.OWEditDomain" title="Edit Domain" version="" />
		<node id="2" name="Test and Score" position="(450, 150)" project_name="Orange3" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" title="Test and Score" version="" />
		<node id="3" name="Random Forest" position="(300, 300)" project_name="Orange3" qualified_name="Orange.widgets.model.owrandomforest.OWRandomForest" title="Random Forest" version="" />
		<node id="4" name="Python Script" position="(900, 300)" project_name="Orange3" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" title="Evaluation_results.py" version="" />
		<node id="5" name="Confusion Matrix" position="(900, 150)" project_name="Orange3" qualified_name="Orange.widgets.evaluate.owconfusionmatrix.OWConfusionMatrix" title="Confusion Matrix" version="" />
		<node id="6" name="Datasets" position="(150, 600)" project_name="Orange3" qualified_name="Orange.widgets.data.owdatasets.OWDataSets" title=" Datasets (iris) (1)" version="" />
		<node id="7" name="Edit Domain" position="(300, 600)" project_name="Orange3" qualified_name="Orange.widgets.data.oweditdomain.OWEditDomain" title="Edit Domain (1)" version="" />
		<node id="8" name="Test and Score" position="(450, 600)" project_name="Orange3" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" title="Test and Score (1)" version="" />
		<node id="9" name="Random Forest" position="(300, 750)" project_name="Orange3" qualified_name="Orange.widgets.model.owrandomforest.OWRandomForest" title="Random Forest (1)" version="" />
		<node id="10" name="Python Script" position="(900, 600)" project_name="Orange3" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" title="Evaluation_results.py (1)" version="" />
		<node id="11" name="Feature Constructor" position="(600, 750)" project_name="Orange3" qualified_name="Orange.widgets.data.owfeatureconstructor.OWFeatureConstructor" title="Feature Constructor" version="" />
		<node id="12" name="Select Columns" position="(751.0, 750.0)" project_name="Orange3" qualified_name="Orange.widgets.data.owselectcolumns.OWSelectAttributes" title="Select Columns" version="" />
		<node id="13" name="ROC Analysis" position="(600, 900)" project_name="Orange3" qualified_name="Orange.widgets.evaluate.owrocanalysis.OWROCAnalysis" title="ROC Analysis" version="" />
		<node id="14" name="Python Script" position="(909.0, 750.0)" project_name="Orange3" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" title="Evaluation_results.py (2)" version="" />
	</nodes>
	<links>
		<link enabled="true" id="0" sink_channel="Data" sink_node_id="1" source_channel="Data" source_node_id="0" />
		<link enabled="true" id="1" sink_channel="Data" sink_node_id="2" source_channel="Data" source_node_id="1" />
		<link enabled="true" id="2" sink_channel="Learner" sink_node_id="2" source_channel="Learner" source_node_id="3" />
		<link enabled="true" id="3" sink_channel="Data" sink_node_id="4" source_channel="Predictions" source_node_id="2" />
		<link enabled="true" id="4" sink_channel="Evaluation Results" sink_node_id="5" source_channel="Evaluation Results" source_node_id="2" />
		<link enabled="true" id="5" sink_channel="Data" sink_node_id="7" source_channel="Data" source_node_id="6" />
		<link enabled="true" id="6" sink_channel="Data" sink_node_id="8" source_channel="Data" source_node_id="7" />
		<link enabled="true" id="7" sink_channel="Learner" sink_node_id="8" source_channel="Learner" source_node_id="9" />
		<link enabled="true" id="8" sink_channel="Data" sink_node_id="10" source_channel="Predictions" source_node_id="8" />
		<link enabled="true" id="9" sink_channel="Data" sink_node_id="11" source_channel="Predictions" source_node_id="8" />
		<link enabled="true" id="10" sink_channel="Data" sink_node_id="12" source_channel="Data" source_node_id="11" />
		<link enabled="true" id="11" sink_channel="Evaluation Results" sink_node_id="13" source_channel="Evaluation Results" source_node_id="8" />
		<link enabled="true" id="12" sink_channel="Data" sink_node_id="14" source_channel="Data" source_node_id="12" />
	</links>
	<annotations>
		<text font-family="MS Shell Dlg 2" font-size="16" id="0" rect="(120.0, 7.0, 810.0, 101.0)" type="text/markdown">## Calculate Confusion matrix and some other performance criteria (out of Data, not Evaluation Results)
(with the same results as the standard components of course)</text>
		<text font-family="MS Shell Dlg 2" font-size="16" id="1" rect="(130.0, 428.0, 811.0, 101.0)" type="text/markdown">## Use Evaluation results to tweak a models output to optimize a specific performance criteria
(in this example, to optimize Recall of Scrap)</text>
		<arrow end="(254.0, 654.0)" fill="#C1272D" id="2" start="(149.0, 765.0)" />
		<text font-family="MS Shell Dlg 2" font-size="16" id="3" rect="(37.0, 777.0, 191.0, 159.0)" type="text/plain">Edit domain to have two classes (Scrap and OK part)
Use Arrow up and down keys to have Scrap on top of the list!</text>
		<arrow end="(544.0, 807.0)" fill="#C1272D" id="4" start="(402.0, 916.0)" />
		<text font-family="MS Shell Dlg 2" font-size="16" id="5" rect="(167.0, 927.0, 275.0, 119.0)" type="text/plain">Construct a new feature "class" with different threshold, so that all actual Scrap parts are identified (Recall = 1). The precision is worse in comparison to the untweaked model.

The needed decision threshold of about 0.18 can be found in the ROC.</text>
		<arrow end="(918.0, 570.0)" fill="#C1272D" id="6" start="(970.0, 515.0)" />
		<text font-family="MS Shell Dlg 2" font-size="16" id="7" rect="(981.0, 504.0, 218.0, 105.0)" type="text/plain">Confusion matrix of the untweaked model shows some false positives and some false negatives.</text>
		<text font-family="MS Shell Dlg 2" font-size="16" id="8" rect="(992.0, 808.0, 172.0, 146.0)" type="text/plain">See Evaluation results.

Confusion matrix shows no false negatives. All scrap parts are identified.</text>
		<arrow end="(921.0, 806.0)" fill="#C1272D" id="9" start="(983.0, 862.0)" />
		<arrow end="(562.0, 932.0)" fill="#C1272D" id="10" start="(433.0, 1060.0)" />
		<arrow end="(759.0, 810.0)" fill="#C1272D" id="11" start="(799.0, 928.0)" />
		<text font-family="MS Shell Dlg 2" font-size="16" id="12" rect="(744.0, 941.0, 212.0, 119.0)" type="text/plain">Use Select Columns to place the new feature "class" in metas (at the top of the list of metas)</text>
	</annotations>
	<thumbnail />
	<node_properties>
		<properties format="literal" node_id="0">{'controlAreaVisible': True, 'header_state': b"\x00\x00\x00\xff\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x04-\x00\x00\x00\x07\x01\x01\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00d\xff\xff\xff\xff\x00\x00\x00\x81\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00'\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01\x03\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01s\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x03\xe8\x00\x00\x00\x00d", 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd', 'selected_id': 'core\\iris.tab', 'splitter_state': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01,\x00\x00\x00\xc8\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', '__version__': 1}</properties>
		<properties format="pickle" node_id="1">gASVvQEAAAAAAAB9lCiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21ldHJ5
lENCAdnQywADAAAAAACSAAABMQAAAxEAAAMQAAAAkgAAATEAAAMRAAADEAAAAAAAAAAAB4AAAACS
AAABMQAAAxEAAAMQlIwLX192ZXJzaW9uX1+USwKMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9yYW5n
ZXdpZGdldC5zZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMFF9kb21haW5f
Y2hhbmdlX3N0b3JllH2USvz///+GlIwWX21lcmdlX2RpYWxvZ19zZXR0aW5nc5R9lEr8////hpSM
Dl9zZWxlY3RlZF9pdGVtlIwEaXJpc5RLAIaUSv7///+GlIwRb3V0cHV0X3RhYmxlX25hbWWUjACU
Sv7///+GlGgESwJ1jAphdHRyaWJ1dGVzlH2UKIwMc2VwYWwgbGVuZ3RolEsCjAtzZXBhbCB3aWR0
aJRLAowMcGV0YWwgbGVuZ3RolEsCjAtwZXRhbCB3aWR0aJRLAmgVSwF1jAVtZXRhc5R9lHViYXUu
</properties>
		<properties format="pickle" node_id="2">gASVvwIAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSIjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAEaQAAACYAAAdxAAABTgAABGoAAABFAAAHcAAAAU0AAAAAAAAAAAeAAAAE
agAAAEUAAAdwAAABTZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwEUk1TRZSMCVByZWNpc2lvbpSMAkNBlIwCRjGUjANB
VUOUjANNQUWUjAZSZWNhbGyUjANNU0WUjAJSMpSMC1NwZWNpZmljaXR5lJBzjAtfX3ZlcnNpb25f
X5RLA4wQY29udGV4dF9zZXR0aW5nc5RdlIwVb3Jhbmdld2lkZ2V0LnNldHRpbmdzlIwHQ29udGV4
dJSTlCmBlH2UKIwGdmFsdWVzlH2UKIwPY2xhc3Nfc2VsZWN0aW9ulIwOSXJpcy12aXJnaW5pY2GU
Sv////+GlIwMZm9sZF9mZWF0dXJllE5K/v///4aUjBVmb2xkX2ZlYXR1cmVfc2VsZWN0ZWSUiUr+
////hpRoDX2UaBtLA3WMCmF0dHJpYnV0ZXOUKIwMc2VwYWwgbGVuZ3RolEsChpSMC3NlcGFsIHdp
ZHRolEsChpSMDHBldGFsIGxlbmd0aJRLAoaUjAtwZXRhbCB3aWR0aJRLAoaUdJSMBW1ldGFzlCmM
CmNsYXNzX3ZhcnOUjARpcmlzlEsBhpSFlHViYXUu
</properties>
		<properties format="literal" node_id="3">{'auto_apply': True, 'class_weight': False, 'controlAreaVisible': True, 'index_output': 0, 'learner_name': '', 'max_depth': 3, 'max_features': 6, 'min_samples_split': 5, 'n_estimators': 30, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00Q\x00\x00\x025\x00\x00\x01\xb4\x00\x00\x03\x88\x00\x00\x00R\x00\x00\x02T\x00\x00\x01\xb3\x00\x00\x03\x87\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00R\x00\x00\x02T\x00\x00\x01\xb3\x00\x00\x03\x87', 'use_max_depth': False, 'use_max_features': False, 'use_min_samples_split': True, 'use_random_state': True, '__version__': 1}</properties>
		<properties format="literal" node_id="4">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07', 'scriptLibrary': [{'name': 'Evaluation_results', 'script': '# Confusion Matrix and some more Evaluation Results\n#################################\n# Settings:\nTarget_Class = "Iris-versicolor"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}], 'scriptText': '# Confusion Matrix and some more Evaluation Results\n#################################\n# Settings:\nTarget_Class = "Iris-versicolor"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\xf2\x00\x00\x01r\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties format="pickle" node_id="5">gASVxAEAAAAAAAB9lCiMEmFwcGVuZF9wcmVkaWN0aW9uc5SIjBRhcHBlbmRfcHJvYmFiaWxpdGll
c5SJjAphdXRvY29tbWl0lIiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21l
dHJ5lENCAdnQywADAAAAAATSAAAAZQAAB1EAAAGIAAAE0gAAAGUAAAdRAAABiAAAAAAAAAAAB4AA
AATSAAAAZQAAB1EAAAGIlIwQc2VsZWN0ZWRfbGVhcm5lcpSMB2NvcHlyZWeUjA5fcmVjb25zdHJ1
Y3RvcpSTlIwIYnVpbHRpbnOUjARsaXN0lJOUaA0ph5RSlEsAYYwRc2VsZWN0ZWRfcXVhbnRpdHmU
SwCMC19fdmVyc2lvbl9flEsBjBBjb250ZXh0X3NldHRpbmdzlF2UjBVvcmFuZ2V3aWRnZXQuc2V0
dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojAlzZWxlY3Rpb26Uj5RoEUsBdYwH
Y2xhc3Nlc5SMC0lyaXMtc2V0b3NhlIwPSXJpcy12ZXJzaWNvbG9ylIwOSXJpcy12aXJnaW5pY2GU
h5R1YmF1Lg==
</properties>
		<properties format="literal" node_id="6">{'controlAreaVisible': True, 'header_state': b"\x00\x00\x00\xff\x00\x00\x00\x00\x00\x00\x00\x01\x00\x00\x00\x01\x00\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x04-\x00\x00\x00\x07\x01\x01\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00d\xff\xff\xff\xff\x00\x00\x00\x81\x00\x00\x00\x00\x00\x00\x00\x07\x00\x00\x00'\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01\x03\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00d\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x01s\x00\x00\x00\x01\x00\x00\x00\x00\x00\x00\x03\xe8\x00\x00\x00\x00d", 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\x9a\x00\x00\x00\xa9\x00\x00\x05\xe7\x00\x00\x03\xfe\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x01\x9b\x00\x00\x00\xc8\x00\x00\x05\xe6\x00\x00\x03\xfd', 'selected_id': 'core\\iris.tab', 'splitter_state': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01,\x00\x00\x00\xc8\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', '__version__': 1}</properties>
		<properties format="pickle" node_id="7">gASVVAIAAAAAAAB9lCiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21ldHJ5
lENCAdnQywADAAAAAACSAAABMQAAAxEAAAMQAAAAkgAAATEAAAMRAAADEAAAAAAAAAAAB4AAAACS
AAABMQAAAxEAAAMQlIwLX192ZXJzaW9uX1+USwKMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9yYW5n
ZXdpZGdldC5zZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMFF9kb21haW5f
Y2hhbmdlX3N0b3JllH2UjAtDYXRlZ29yaWNhbJQojARpcmlzlIwLSXJpcy1zZXRvc2GUjA9Jcmlz
LXZlcnNpY29sb3KUjA5JcmlzLXZpcmdpbmljYZSHlCmJdJSGlF2UjBFDYXRlZ29yaWVzTWFwcGlu
Z5RdlChoFIwFU2NyYXCUhpRoEowHT0sgcGFydJSGlGgTjAdPSyBwYXJ0lIaUZYWUhpRhc0r+////
hpSMFl9tZXJnZV9kaWFsb2dfc2V0dGluZ3OUfZRK/P///4aUjA5fc2VsZWN0ZWRfaXRlbZRoEUsA
hpRK/v///4aUjBFvdXRwdXRfdGFibGVfbmFtZZSMAJRK/v///4aUaARLAnWMCmF0dHJpYnV0ZXOU
fZQojAxzZXBhbCBsZW5ndGiUSwKMC3NlcGFsIHdpZHRolEsCjAxwZXRhbCBsZW5ndGiUSwKMC3Bl
dGFsIHdpZHRolEsCjARpcmlzlEsBdYwFbWV0YXOUfZR1YmF1Lg==
</properties>
		<properties format="pickle" node_id="8">gASVxwIAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSIjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAEZwAAAVgAAAdvAAACggAABGgAAAF3AAAHbgAAAoEAAAAAAAAAAAeAAAAE
aAAAAXcAAAduAAACgZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwEUk1TRZSMCVByZWNpc2lvbpSMAkYxlIwDQVVDlIwD
TUFFlIwGUmVjYWxslIwDTVNFlIwLU3BlY2lmaWNpdHmUjAJSMpSMAkNBlJBzjAtfX3ZlcnNpb25f
X5RLA4wQY29udGV4dF9zZXR0aW5nc5RdlIwVb3Jhbmdld2lkZ2V0LnNldHRpbmdzlIwHQ29udGV4
dJSTlCmBlH2UKIwGdmFsdWVzlH2UKIwPY2xhc3Nfc2VsZWN0aW9ulIwWKEF2ZXJhZ2Ugb3ZlciBj
bGFzc2VzKZRK/////4aUjAxmb2xkX2ZlYXR1cmWUTkr+////hpSMFWZvbGRfZmVhdHVyZV9zZWxl
Y3RlZJSJSv7///+GlGgNfZRoG0sDdYwKYXR0cmlidXRlc5QojAxzZXBhbCBsZW5ndGiUSwKGlIwL
c2VwYWwgd2lkdGiUSwKGlIwMcGV0YWwgbGVuZ3RolEsChpSMC3BldGFsIHdpZHRolEsChpR0lIwF
bWV0YXOUKYwKY2xhc3NfdmFyc5SMBGlyaXOUSwGGlIWUdWJhdS4=
</properties>
		<properties format="literal" node_id="9">{'auto_apply': True, 'class_weight': False, 'controlAreaVisible': True, 'index_output': 0, 'learner_name': '', 'max_depth': 3, 'max_features': 6, 'min_samples_split': 5, 'n_estimators': 30, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00Q\x00\x00\x025\x00\x00\x01\xb4\x00\x00\x03\x88\x00\x00\x00R\x00\x00\x02T\x00\x00\x01\xb3\x00\x00\x03\x87\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00R\x00\x00\x02T\x00\x00\x01\xb3\x00\x00\x03\x87', 'use_max_depth': False, 'use_max_features': False, 'use_min_samples_split': True, 'use_random_state': True, '__version__': 1}</properties>
		<properties format="literal" node_id="10">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\r\x00\x00\x00|\x00\x00\x06\xfb\x00\x00\x03\x07', 'scriptLibrary': [{'name': 'Evaluation_results', 'script': '# Confusion Matrix and some more Evaluation Results\n#################################\n# Settings:\nTarget_Class = "Scrap"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}], 'scriptText': '# Confusion Matrix and some more Evaluation Results\n#################################\n# Settings:\nTarget_Class = "Scrap"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\xf2\x00\x00\x01r\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties format="pickle" node_id="11">gASVvgQAAAAAAAB9lCiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNzYXZlZFdpZGdldEdlb21ldHJ5
lENCAdnQywADAAAAAABxAAABZwAAAvAAAANGAAAAcQAAAWcAAALwAAADRgAAAAAAAAAAB4AAAABx
AAABZwAAAvAAAANGlIwLX192ZXJzaW9uX1+USwKMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFu
Z2V3aWRnZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojAxjdXJyZW50
SW5kZXiUSwBK/v///4aUjAtkZXNjcmlwdG9yc5RdlIwoT3JhbmdlLndpZGdldHMuZGF0YS5vd2Zl
YXR1cmVjb25zdHJ1Y3RvcpSMEkRpc2NyZXRlRGVzY3JpcHRvcpSTlCiMBWNsYXNzlIwzMCBpZiBS
YW5kb21fRm9yZXN0X18xX19fU2NyYXBfICAgID4gIDAuMTggICAgZWxzZSAxlIwFU2NyYXCUjAdP
SyBwYXJ0lIaUiXSUgZRhjBdleHByZXNzaW9uc193aXRoX3ZhbHVlc5SJSv7///+GlGgESwJ1jAph
dHRyaWJ1dGVzlH2UKIwMc2VwYWwgbGVuZ3RolEsCjAtzZXBhbCB3aWR0aJRLAowMcGV0YWwgbGVu
Z3RolEsCjAtwZXRhbCB3aWR0aJRLAowEaXJpc5RLAXWMBW1ldGFzlH2UKIwRUmFuZG9tIEZvcmVz
dCAoMSmUSwGMGVJhbmRvbSBGb3Jlc3QgKDEpIChTY3JhcCmUSwKMG1JhbmRvbSBGb3Jlc3QgKDEp
IChPSyBwYXJ0KZRLAowERm9sZJRLAXV1YmgJKYGUfZQoaAx9lChoDksASv7///+GlGgQXZRoFCiM
BWNsYXNzlIw7MCBpZiBSYW5kb21fRm9yZXN0X18xX19fSXJpc192aXJnaW5pY2FfID4gICAgMC4x
OCAgICBlbHNlIDGUjA5JcmlzLXZpcmdpbmljYZSMEm5vdCBJcmlzLXZpcmdpbmljYZSGlIl0lIGU
YWgciUr+////hpRoBEsCdWgefZQoaCBLAmghSwJoIksCaCNLAmgkSwF1aCV9lChoJ0sBjCJSYW5k
b20gRm9yZXN0ICgxKSAoSXJpcy12aXJnaW5pY2EplEsCjCZSYW5kb20gRm9yZXN0ICgxKSAobm90
IElyaXMtdmlyZ2luaWNhKZRLAmgqSwF1dWJoCSmBlH2UKGgMfZQoaA5LAEr+////hpRoEF2UaBQo
jAVjbGFzc5SMNTAgaWYgUmFuZG9tX0ZvcmVzdF9fMV9fX0lyaXNfdmVyc2ljb2xvcl8gPiAwLjUg
ZWxzZSAxlIwPSXJpcy12ZXJzaWNvbG9ylIwTbm90IElyaXMtdmVyc2ljb2xvcpSGlIl0lIGUYWgc
iUr+////hpRoBEsCdWgefZQoaCBLAmghSwJoIksCaCNLAmgkSwF1aCV9lChoJ0sBjCNSYW5kb20g
Rm9yZXN0ICgxKSAoSXJpcy12ZXJzaWNvbG9yKZRLAownUmFuZG9tIEZvcmVzdCAoMSkgKG5vdCBJ
cmlzLXZlcnNpY29sb3IplEsCaCpLAXV1YmV1Lg==
</properties>
		<properties format="pickle" node_id="12">gASVBwgAAAAAAAB9lCiMC2F1dG9fY29tbWl0lIiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNpZ25v
cmVfbmV3X2ZlYXR1cmVzlImME3NhdmVkV2lkZ2V0R2VvbWV0cnmUQ0IB2dDLAAMAAAAAAQkAAADq
AAADiAAAAskAAAEJAAAA6gAAA4gAAALJAAAAAAAAAAAHgAAAAQkAAADqAAADiAAAAsmUjBJ1c2Vf
aW5wdXRfZmVhdHVyZXOUiYwLX192ZXJzaW9uX1+USwGMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVv
cmFuZ2V3aWRnZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojBFkb21h
aW5fcm9sZV9oaW50c5R9lCiMC3NlcGFsIHdpZHRolEsChpSMCWF2YWlsYWJsZZRLAIaUjAxzZXBh
bCBsZW5ndGiUSwKGlGgVSwGGlIwLcGV0YWwgd2lkdGiUSwKGlIwJYXR0cmlidXRllEsAhpSMDHBl
dGFsIGxlbmd0aJRLAoaUaBxLAYaUjARpcmlzlEsBhpSMBWNsYXNzlEsAhpSMBWNsYXNzlEsBhpSM
BG1ldGGUSwCGlIwRUmFuZG9tIEZvcmVzdCAoMSmUSwGGlGgnSwGGlIwZUmFuZG9tIEZvcmVzdCAo
MSkgKFNjcmFwKZRLAoaUaCdLAoaUjBtSYW5kb20gRm9yZXN0ICgxKSAoT0sgcGFydCmUSwKGlGgn
SwOGlIwERm9sZJRLAYaUaCdLBIaUdUr+////hpRoB0sBdYwKYXR0cmlidXRlc5R9lChoF0sCaBNL
AmgeSwJoGksCjAVjbGFzc5RLAWghSwF1jAVtZXRhc5R9lChoKUsBaCxLAmgvSwJoMksBdXViaAwp
gZR9lChoD32UKGgRfZQoaBNLAoaUaBVLAIaUaBdLAoaUaBVLAYaUaBpLAoaUaBxLAIaUaB5LAoaU
aBxLAYaUaCFLAYaUaCNLAIaUaClLAYaUaCdLAIaUaCxLAoaUaCdLAYaUaC9LAoaUaCdLAoaUaDJL
AYaUaCdLA4aUdUr+////hpRoB0sBdWg2fZQoaBdLAmgTSwJoHksCaBpLAmghSwF1aDl9lChoKUsB
aCxLAmgvSwJoMksBdXViaAwpgZR9lChoD32UKGgRfZQoaBNLAoaUaBVLAIaUaBdLAoaUaBVLAYaU
aBpLAoaUaBxLAIaUaB5LAoaUaBxLAYaUjAZjbGFzc2WUSwGGlGgcSwKGlGghSwGGlGgjSwCGlGgp
SwGGlGgnSwCGlGgsSwKGlGgnSwGGlGgvSwKGlGgnSwKGlGgySwGGlGgnSwOGlHVK/v///4aUaAdL
AXVoNn2UKGgXSwJoE0sCaB5LAmgaSwJoYEsBaCFLAXVoOX2UKGgpSwFoLEsCaC9LAmgySwF1dWJo
DCmBlH2UKGgPfZQoaBF9lChoE0sChpRoFUsAhpRoF0sChpRoFUsBhpRoKUsBhpRoFUsChpRoLEsC
hpRoFUsDhpRoL0sChpRoFUsEhpRoMksBhpRoFUsFhpRoGksChpRoHEsAhpRoHksChpRoHEsBhpSM
AkQxlEsBhpRoHEsChpRoIUsBhpRoI0sAhpR1Sv7///+GlGgHSwF1aDZ9lChoF0sCaBNLAmgeSwJo
GksCaIRLAWghSwF1aDl9lChoKUsBaCxLAmgvSwJoMksBdXViaAwpgZR9lChoD32UKGgRfZQoaClL
AYaUaBVLAIaUjCNSYW5kb20gRm9yZXN0ICgxKSAoSXJpcy12ZXJzaWNvbG9yKZRLAoaUaBVLAYaU
jCdSYW5kb20gRm9yZXN0ICgxKSAobm90IElyaXMtdmVyc2ljb2xvcimUSwKGlGgVSwKGlGgySwGG
lGgVSwOGlGgaSwKGlGgcSwCGlGgeSwKGlGgcSwGGlGgTSwKGlGgcSwKGlGgXSwKGlGgcSwOGlGgh
SwGGlGgjSwCGlIwFY2xhc3OUSwGGlGgnSwCGlHVK/v///4aUaAdLAXVoNn2UKGgXSwJoE0sCaB5L
AmgaSwKMBWNsYXNzlEsBaCFLAXVoOX2UKGgpSwFokksCaJVLAmgySwF1dWJoDCmBlH2UKGgPfZQo
aBF9lChoE0sChpRoFUsAhpRoF0sChpRoFUsBhpRoKUsBhpRoFUsChpSMIlJhbmRvbSBGb3Jlc3Qg
KDEpIChJcmlzLXZpcmdpbmljYSmUSwKGlGgVSwOGlIwmUmFuZG9tIEZvcmVzdCAoMSkgKG5vdCBJ
cmlzLXZpcmdpbmljYSmUSwKGlGgVSwSGlGgySwGGlGgVSwWGlGgaSwKGlGgcSwCGlGgeSwKGlGgc
SwGGlGghSwGGlGgjSwCGlIwFY2xhc3OUSwGGlGgnSwCGlHVK/v///4aUaAdLAXVoNn2UKGgXSwJo
E0sCaB5LAmgaSwKMBWNsYXNzlEsBaCFLAXVoOX2UKGgpSwFotUsCaLhLAmgySwF1dWJoDCmBlH2U
KGgPfZQoaBF9lChoE0sChpRoFUsAhpRoF0sChpRoFUsBhpRoGksChpRoHEsAhpRoHksChpRoHEsB
hpRoIUsBhpRoI0sAhpRoKUsBhpRoJ0sAhpRotUsChpRoJ0sBhpRouEsChpRoJ0sChpRoMksBhpRo
J0sDhpR1Sv7///+GlGgHSwF1aDZ9lChoF0sCaBNLAmgeSwJoGksCaCFLAXVoOX2UKGgpSwFotUsC
aLhLAmgySwF1dWJldS4=
</properties>
		<properties format="pickle" node_id="13">gASVTQIAAAAAAAB9lCiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBRkaXNwbGF5X2NvbnZleF9jdXJ2
ZZSJjBNkaXNwbGF5X2NvbnZleF9odWxslImMFWRpc3BsYXlfZGVmX3RocmVzaG9sZJSJjBFkaXNw
bGF5X3BlcmZfbGluZZSJjAdmbl9jb3N0lE3oA4wHZnBfY29zdJRL8IwNcm9jX2F2ZXJhZ2luZ5RL
AIwTc2F2ZWRXaWRnZXRHZW9tZXRyeZRDQgHZ0MsAAwAAAAAAAAAAABcAAAd/AAAEhwAAAAAAAAAX
AAAHfwAABIcAAAAAAgAAAAeAAAAAAAAAABcAAAd/AAAEh5SMDHRhcmdldF9wcmlvcpSMFW51bXB5
LmNvcmUubXVsdGlhcnJheZSMBnNjYWxhcpSTlIwFbnVtcHmUjAVkdHlwZZSTlIwCZjiUiYiHlFKU
KEsDjAE8lE5OTkr/////Sv////9LAHSUYkMIAAAAAACAQECUhpRSlIwLX192ZXJzaW9uX1+USwGM
EGNvbnRleHRfc2V0dGluZ3OUXZSMFW9yYW5nZXdpZGdldC5zZXR0aW5nc5SMB0NvbnRleHSUk5Qp
gZR9lCiMBnZhbHVlc5R9lCiMFHNlbGVjdGVkX2NsYXNzaWZpZXJzlF2USwBhjAx0YXJnZXRfaW5k
ZXiUSwBoGksBdYwHY2xhc3Nlc5SMBVNjcmFwlIwHT0sgcGFydJSGlIwQY2xhc3NpZmllcl9uYW1l
c5RdlIwRUmFuZG9tIEZvcmVzdCAoMSmUYXViYXUu
</properties>
		<properties format="literal" node_id="14">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03f\x00\x00\x00(\x00\x00\x07V\x00\x00\x02\xd3\x00\x00\x03g\x00\x00\x00G\x00\x00\x07U\x00\x00\x02\xd2\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03g\x00\x00\x00G\x00\x00\x07U\x00\x00\x02\xd2', 'scriptLibrary': [{'name': 'Evaluation_results', 'script': '# Confusion Matrix and some more Evaluation Results\n####################################################\n# Settings:\nTarget_Class = "Scrap"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}], 'scriptText': '# Confusion Matrix and some more Evaluation Results\n####################################################\n# Settings:\nTarget_Class = "Scrap"\n# Target Class or positive Class for calculation \n# of Evaluation Results other than Confusion matrix\n# and CA\n\n#####################################################\n# File: Evaluation_results.py\n\n"""\n* Widget input: data\n    - predicted values as metas (must be the first item in metas!)\n    (If necessary, use Select Columns Widget to shape the data accordingly)\n    - target\n    Sequence of classes must be the same in target and metas! \n    Use Edit Domain widget to ensure this.\n\n    Data may or may not contain features.\n\nUsage:\n* Widget output: \n    - no output, results are printed in this Widget.\n\n* Select a Target Class or positive Class for calculation.\n* Computes Confusion matrix and some more Evaluation results\n  out of data with predicted values and target.\n* For example, if predicted values are generated with Feature\n  Constructor Widget with a special Threshold to tweak a model.\n\n"""\n\n\nimport Orange\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\nfrom math import sqrt\n\ndata = in_data\n#X = data.X\n#y = data.Y\n\nif Target_Class in data.domain.class_var.values:\n\n    y_true = data.Y.astype(int)\n    y_pred = data.metas[:,0].astype(int)\n\n    # calculating confusion matrix and CA\n    cfmatrix = confusion_matrix(y_true, y_pred)\n    CA = np.sum(np.diagonal(cfmatrix))/np.sum(cfmatrix)\n\n    # calculating the other performance criteria\n    positive_class = data.domain.class_var.values.index(Target_Class)\n    matrix = np.zeros([2,2])\n    matrix[0,0] = cfmatrix[positive_class, positive_class]\n    matrix[1,0] = np.sum(cfmatrix[:, positive_class]) - matrix[0,0]\n    matrix[0,1] = np.sum(cfmatrix[positive_class, :]) - matrix[0,0]\n    matrix[1,1] = np.sum(cfmatrix) - matrix[0,0] - matrix[0,1] - matrix[1,0]\n\n    precision = matrix[0,0]/np.sum(matrix[:,0])\n    recall = matrix[0,0]/np.sum(matrix[0,:])\n    specificity = matrix[1,1]/np.sum(matrix[1,:])\n    F1_score = 2/((1/precision)+(1/recall))\n\n    # calculate Matthews correlation coefficient\n    tp = matrix[0,0]\n    tn = matrix[1,1]\n    fp = matrix[1,0]\n    fn = matrix[0,1]\n    MCC = (tp*tn-fp*fn)/sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))\n    # There is also a sklearn-function for calculation of MCC out of y_true and y_pred.\n    # But because confusion matrix is already calculated, this should be faster, I think.\n\n    print("")\n    print("-------------------------------")\n    print("Confusion matrix:")\n    print("-------------------------------")\n    print("            \\u2193 actual predicted \\u2192")\n    print("                     ", end="")\n\n    for item in data.domain.metas[0].values:\n        print(item.ljust(20)[:20]+" ", end="")\n\n    num_classes = len(data.domain.class_var.values)\n    for i in range(num_classes):\n        print("\\n"+data.domain.class_var.values[i].rjust(20)[:20]+" ", end="")\n        for j in range(num_classes):\n            print(f"{cfmatrix[i,j]}".ljust(21), end="")\n\n    print()\n    print()\n    print(f"CA:            {CA:1.3}")\n    print(f"Precision:     {precision:1.3}")\n    print(f"Recall:        {recall:1.3}")\n    print(f"Specificity:   {specificity:1.3}")\n    print(f"F1_score:      {F1_score:1.3}")\n    print(f"MCC:           {MCC:1.3}")\n\n    print("Target Class (positive Class): ", Target_Class)\n\nelse:\n    print("-------------------------------------------------")\n    print("Select a Target Class out of the current Classes:")\n    for item in data.domain.class_var.values:\n        print(item +", ", end="")\n    print("-------------------------------------------------")\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x00\xf2\x00\x00\x01r\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
