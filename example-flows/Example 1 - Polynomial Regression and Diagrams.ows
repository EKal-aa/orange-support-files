<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="" description="">
	<nodes>
		<node id="0" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Poly_Regression.py" position="(356.0, 757.0)" />
		<node id="1" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions2D.py" position="(662.0, 754.0)" />
		<node id="2" name="Paint Data" qualified_name="Orange.widgets.data.owpaintdata.OWPaintData" project_name="Orange3" version="" title="Paint Data" position="(83.0, 149.0)" />
		<node id="3" name="Linear Regression" qualified_name="Orange.widgets.model.owlinearregression.OWLinearRegression" project_name="Orange3" version="" title="Linear Regression" position="(363.0, 253.0)" />
		<node id="4" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="PolyFeatures.py" position="(365.0, 150.0)" />
		<node id="5" name="Select Columns" qualified_name="Orange.widgets.data.owselectcolumns.OWSelectAttributes" project_name="Orange3" version="" title="Select Columns" position="(182.0, 149.0)" />
		<node id="6" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score" position="(483.0, 151.0)" />
		<node id="7" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table" position="(488.0, 53.0)" />
		<node id="8" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table" position="(309.0, 51.0)" />
		<node id="9" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score" position="(473.0, 687.0)" />
		<node id="10" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table" position="(666.0, 52.0)" />
		<node id="11" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (just forwarding the data)" position="(149.0, 416.0)" />
		<node id="12" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score" position="(477.0, 422.0)" />
		<node id="13" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Poly_Regression.py" position="(361.0, 498.0)" />
		<node id="14" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (just forwarding the data)" position="(133.0, 684.0)" />
		<node id="15" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (4)" position="(659.0, 317.0)" />
		<node id="16" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Poly_Regression.py" position="(362.0, 1051.0)" />
		<node id="17" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions2D.py" position="(668.0, 1048.0)" />
		<node id="18" name="Test and Score" qualified_name="Orange.widgets.evaluate.owtestandscore.OWTestAndScore" project_name="Orange3" version="" title="Test and Score" position="(479.0, 981.0)" />
		<node id="19" name="Data Table" qualified_name="Orange.widgets.data.owtable.OWDataTable" project_name="Orange3" version="" title="Data Table (just forwarding the data)" position="(139.0, 978.0)" />
		<node id="20" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions.py" position="(664.0, 151.0)" />
		<node id="21" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions.py" position="(659.0, 423.0)" />
	</nodes>
	<links>
		<link id="0" source_node_id="2" sink_node_id="5" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="1" source_node_id="5" sink_node_id="4" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="2" source_node_id="4" sink_node_id="6" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="3" source_node_id="3" sink_node_id="6" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="4" source_node_id="4" sink_node_id="7" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="5" source_node_id="5" sink_node_id="8" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="6" source_node_id="0" sink_node_id="9" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="7" source_node_id="9" sink_node_id="1" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="8" source_node_id="0" sink_node_id="1" source_channel="Classifier" sink_channel="Classifier" enabled="true" />
		<link id="9" source_node_id="6" sink_node_id="10" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="10" source_node_id="5" sink_node_id="11" source_channel="Data" sink_channel="Data" enabled="true" />
		<link id="11" source_node_id="13" sink_node_id="12" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="12" source_node_id="14" sink_node_id="9" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="13" source_node_id="11" sink_node_id="12" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="14" source_node_id="14" sink_node_id="0" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="15" source_node_id="12" sink_node_id="15" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="16" source_node_id="16" sink_node_id="18" source_channel="Learner" sink_channel="Learner" enabled="true" />
		<link id="17" source_node_id="18" sink_node_id="17" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="18" source_node_id="16" sink_node_id="17" source_channel="Classifier" sink_channel="Classifier" enabled="true" />
		<link id="19" source_node_id="19" sink_node_id="18" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="20" source_node_id="19" sink_node_id="16" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="21" source_node_id="11" sink_node_id="14" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="22" source_node_id="14" sink_node_id="19" source_channel="Selected Data" sink_channel="Data" enabled="true" />
		<link id="23" source_node_id="6" sink_node_id="20" source_channel="Predictions" sink_channel="Data" enabled="true" />
		<link id="24" source_node_id="12" sink_node_id="21" source_channel="Predictions" sink_channel="Data" enabled="true" />
	</links>
	<annotations>
		<arrow id="0" start="(480.0, 553.0)" end="(401.0, 514.0)" fill="#C1272D" />
		<text id="1" type="text/plain" rect="(492.0, 518.0, 208.0, 103.0)" font-family="MS Shell Dlg 2" font-size="16">let it run once to get outputs (otherwise the connection line is a dashed line, indicating that there is no output)</text>
		<text id="2" type="text/plain" rect="(258.0, -82.0, 109.0, 52.0)" font-family="MS Shell Dlg 2" font-size="16">only feature x and target y</text>
		<text id="3" type="text/plain" rect="(419.0, -83.0, 142.0, 52.0)" font-family="MS Shell Dlg 2" font-size="16">added features from PolyFeatures</text>
		<arrow id="4" start="(309.0, -29.0)" end="(311.0, 19.0)" fill="#C1272D" />
		<arrow id="5" start="(488.0, -33.0)" end="(487.0, 20.0)" fill="#C1272D" />
		<text id="6" type="text/plain" rect="(757.0, -92.0, 150.0, 27.0)" font-family="MS Shell Dlg 2" font-size="16">as expected, also columns for predictions and fold are in the data</text>
		<arrow id="7" start="(751.0, -10.0)" end="(701.0, 30.0)" fill="#C1272D" />
		<arrow id="8" start="(759.0, 144.0)" end="(705.0, 150.0)" fill="#C1272D" />
		<text id="9" type="text/plain" rect="(778.0, 128.0, 150.0, 31.0)" font-family="MS Shell Dlg 2" font-size="16">see the diagram</text>
		<text id="10" type="text/plain" rect="(768.0, 263.0, 150.0, 27.0)" font-family="MS Shell Dlg 2" font-size="16">no added features in the data with Poly_Regression</text>
		<arrow id="11" start="(752.0, 313.0)" end="(700.0, 318.0)" fill="#C1272D" />
		<text id="12" type="text/plain" rect="(790.0, 392.0, 150.0, 27.0)" font-family="MS Shell Dlg 2" font-size="16">see the diagram
(just like above)</text>
		<arrow id="13" start="(757.0, 416.0)" end="(704.0, 420.0)" fill="#C1272D" />
		<arrow id="14" start="(504.0, 846.0)" end="(504.0, 768.0)" fill="#C1272D" />
		<text id="15" type="text/plain" rect="(453.0, 839.0, 150.0, 27.0)" font-family="MS Shell Dlg 2" font-size="16">now a classifier is used</text>
		<text id="16" type="text/plain" rect="(814.0, 692.0, 317.0, 186.0)" font-family="MS Shell Dlg 2" font-size="16">see the diagram.
With Diagram_target_predictions2D, the model is used to compute the values  for model prediction. They don't come from the data. So the model can be shown not only for the training instances.</text>
		<arrow id="17" start="(793.0, 749.0)" end="(710.0, 751.0)" fill="#C1272D" />
		<arrow id="18" start="(378.0, 1191.0)" end="(366.0, 1120.0)" fill="#C1272D" />
		<text id="19" type="text/plain" rect="(328.0, 1191.0, 162.0, 69.0)" font-family="MS Shell Dlg 2" font-size="16">now with degree 15, so overfitting will occur</text>
		<text id="20" type="text/plain" rect="(816.0, 995.0, 150.0, 27.0)" font-family="MS Shell Dlg 2" font-size="16">see the diagram.
Overfitting is clearly visible.
</text>
		<arrow id="21" start="(799.0, 1045.0)" end="(710.0, 1047.0)" fill="#C1272D" />
		<text id="22" type="text/markdown" rect="(-199.0, 86.0, 218.0, 137.0)" font-family="MS Shell Dlg 2" font-size="16">## PolyFeatures.py and Diagram_targe_predictions.py</text>
		<text id="23" type="text/markdown" rect="(-199.0, 384.0, 259.0, 50.0)" font-family="MS Shell Dlg 2" font-size="16">## Poly_Regression.py</text>
		<text id="24" type="text/markdown" rect="(-196.0, 658.0, 224.0, 79.0)" font-family="MS Shell Dlg 2" font-size="16">## Diagram_target-Predictions2D.py</text>
		<text id="25" type="text/markdown" rect="(-198.0, 953.0, 150.0, 41.0)" font-family="MS Shell Dlg 2" font-size="16">## Overfitting</text>
		<text id="26" type="text/markdown" rect="(-187.0, -238.0, 1121.0, 129.0)" font-family="MS Shell Dlg 2" font-size="16"># Example with PolyFeatures.py, Poly_Regression.py, Diagram_target_predictions.py and Diagram_target_predictions2D.py  
(one numerical features and one numerical target)</text>
	</annotations>
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0', 'scriptLibrary': [{'name': 'Poly_Regression.py', 'script': '# Polynomial Regression\n########################################################\n# Settings:\nname="1"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 1            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - learner and trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}], 'scriptText': '# Polynomial Regression\n########################################################\n# Settings:\nname="1"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 5            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xbd\x00\x00\x00\xce\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="1" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E', 'scriptLibrary': [{'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 2         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}], 'scriptText': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="2" format="literal">{'attr1': 'x', 'attr2': 'y', 'autocommit': True, 'brushRadius': 75, 'controlAreaVisible': True, 'data': [[0.010783383940286703, 0.2975030783573148, 0.0], [0.03986075344251205, 0.39217818853493247, 0.0], [0.1034096671190359, 0.580015004946324, 0.0], [0.2001679297338846, 0.6442898508125617, 0.0], [0.24012517160500768, 0.6252587096432315, 0.0], [0.1765345837004807, 0.6883116330005694, 0.0], [0.319139273272614, 0.5503320615590699, 0.0], [0.2727175837559706, 0.5698915971509196, 0.0], [0.36302961379158316, 0.414457345153919, 0.0], [0.47255476747510516, 0.32480575096127523, 0.0], [0.5123974137789061, 0.31494590794886507, 0.0], [0.5177860889287595, 0.23531369187884774, 0.0], [0.5968418734706349, 0.24677082096034675, 0.0], [0.699690850241529, 0.2953692189430633, 0.0], [0.7637234000537376, 0.3688185878777299, 0.0], [0.7611171450286315, 0.4646600100832098, 0.0], [0.7958099741137518, 0.5177069716354361, 0.0], [0.8353259404327023, 0.7506503178367862, 0.0], [0.94303129513231, 0.8331918196557742, 0.0], [0.9081110937298393, 0.8642934317010036, 0.0]], 'density': 1, 'hasAttr2': True, 'labels': ['C1', 'C2'], 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00\x0b\x00\x00\x00\x0c\x00\x00\x04x\x00\x00\x03\x08\x00\x00\x00\x0c\x00\x00\x00+\x00\x00\x04w\x00\x00\x03\x07\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00\x0c\x00\x00\x00+\x00\x00\x04w\x00\x00\x03\x07', 'symbol_size': 10, 'table_name': 'Painted data', '__version__': 1}</properties>
		<properties node_id="3" format="literal">{'alpha_index': 0, 'auto_apply': True, 'autosend': True, 'controlAreaVisible': True, 'fit_intercept': True, 'l2_ratio': 0.5, 'learner_name': '', 'reg_type': 0, 'ridge': False, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x01d\x00\x00\x04X\x00\x00\x02\xdb\x00\x00\x03\x11\x00\x00\x01\x83\x00\x00\x04W\x00\x00\x02\xda\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x01\x83\x00\x00\x04W\x00\x00\x02\xda', '__version__': 1}</properties>
		<properties node_id="4" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02(\x00\x00\x00i\x00\x00\x05\xb1\x00\x00\x03=\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xb0\x00\x00\x03&lt;\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xb0\x00\x00\x03&lt;', 'scriptLibrary': [{'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\n* Widget input: data (only numerical features are used; categorical features are filtered out)\n* Widget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names_out())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names_out()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}], 'scriptText': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 5     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\n* Widget input: data (only numerical features are used; categorical features are filtered out)\n* Widget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names_out())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names_out()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="5" format="pickle">gASVgwEAAAAAAAB9lCiMC2F1dG9fY29tbWl0lIiMEmNvbnRyb2xBcmVhVmlzaWJsZZSIjBNpZ25v
cmVfbmV3X2ZlYXR1cmVzlImME3NhdmVkV2lkZ2V0R2VvbWV0cnmUQ0IB2dDLAAMAAAAAAJcAAADK
AAADhQAAAsgAAACYAAAA6QAAA4QAAALHAAAAAAAAAAAHgAAAAJgAAADpAAADhAAAAseUjBJ1c2Vf
aW5wdXRfZmVhdHVyZXOUiYwLX192ZXJzaW9uX1+USwGMEGNvbnRleHRfc2V0dGluZ3OUXZSMFW9y
YW5nZXdpZGdldC5zZXR0aW5nc5SMB0NvbnRleHSUk5QpgZR9lCiMBnZhbHVlc5R9lCiMEWRvbWFp
bl9yb2xlX2hpbnRzlH2UKIwBeJRLAoaUjAlhdHRyaWJ1dGWUSwCGlIwBeZRLAoaUjAVjbGFzc5RL
AIaUdUr+////hpRoB0sBdYwKYXR0cmlidXRlc5R9lChoE0sCaBdLAnWMBW1ldGFzlH2UdWJhdS4=
</properties>
		<properties node_id="6" format="pickle">gASVHwMAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSJjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAC7AAAAWEAAAX3AAADOQAAAuwAAAFhAAAF9wAAAzkAAAAAAAAAAAeAAAAC
7AAAAWEAAAX3AAADOZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwCQ0GUjANBVUOUjANNQUWUjARSTVNFlIwGUmVjYWxs
lIwCUjKUjAlQcmVjaXNpb26UjANNU0WUjAJGMZSMDVRlc3QgdGltZSBbc12UjA5UcmFpbiB0aW1l
IFtzXZSQc4wLX192ZXJzaW9uX1+USwOMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFuZ2V3aWRn
ZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojA9jbGFzc19zZWxlY3Rp
b26UjBYoQXZlcmFnZSBvdmVyIGNsYXNzZXMplEr/////hpSMDGZvbGRfZmVhdHVyZZROSv7///+G
lIwVZm9sZF9mZWF0dXJlX3NlbGVjdGVklIlK/v///4aUaA19lGgcSwN1jAphdHRyaWJ1dGVzlCiM
AngwlEsChpSMBHgwXjKUSwKGlIwEeDBeM5RLAoaUjAR4MF40lEsChpSMBHgwXjWUSwKGlHSUjAVt
ZXRhc5QpjApjbGFzc192YXJzlIwBeZRLAoaUhZR1YmghKYGUfZQoaCR9lChoJmgnSv////+GlGgp
Tkr+////hpRoK4lK/v///4aUaA19lGgcSwN1aC6MAngwlEsChpSMBHgwXjKUSwKGlIaUaDopaDto
PEsChpSFlHViZXUu
</properties>
		<properties node_id="7" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x89\x00\x00\x02a\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x89\x00\x00\x02a\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x89\x00\x00\x02a', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="8" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x00F\x00\x00\x06\x82\x00\x00\x04\x0f\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="9" format="pickle">gASVxQMAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSJjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAC7AAAAWEAAAX3AAADOQAAAuwAAAFhAAAF9wAAAzkAAAAAAAAAAAeAAAAC
7AAAAWEAAAX3AAADOZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwCQ0GUjANBVUOUjANNQUWUjARSTVNFlIwGUmVjYWxs
lIwCUjKUjAlQcmVjaXNpb26UjANNU0WUjAJGMZSMDVRlc3QgdGltZSBbc12UjA5UcmFpbiB0aW1l
IFtzXZSQc4wLX192ZXJzaW9uX1+USwOMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFuZ2V3aWRn
ZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojA9jbGFzc19zZWxlY3Rp
b26UjBYoQXZlcmFnZSBvdmVyIGNsYXNzZXMplEr/////hpSMDGZvbGRfZmVhdHVyZZROSv7///+G
lIwVZm9sZF9mZWF0dXJlX3NlbGVjdGVklIlK/v///4aUaA19lGgcSwN1jAphdHRyaWJ1dGVzlIwB
eJRLAoaUhZSMBW1ldGFzlCmMCmNsYXNzX3ZhcnOUjAF5lEsChpSFlHViaCEpgZR9lChoJH2UKIwP
Y2xhc3Nfc2VsZWN0aW9ulIwWKEF2ZXJhZ2Ugb3ZlciBjbGFzc2VzKZRK/////4aUjAxmb2xkX2Zl
YXR1cmWUTkr+////hpSMFWZvbGRfZmVhdHVyZV9zZWxlY3RlZJSJSv7///+GlIwLc2NvcmVfdGFi
bGWUfZRoHEsDdWguKIwCeDCUSwKGlIwEeDBeMpRLAoaUjAR4MF4zlEsChpSMBHgwXjSUSwKGlIwE
eDBeNZRLAoaUdJRoMiloM2g0SwKGlIWUdWJoISmBlH2UKGgkfZQoaDpoO0r/////hpRoPU5K/v//
/4aUaD+JSv7///+GlGhBfZRoHEsDdWgujAJ4MJRLAoaUjAR4MF4ylEsChpSGlGgyKWgzaDRLAoaU
hZR1YmV1Lg==
</properties>
		<properties node_id="10" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="11" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="12" format="pickle">gASV8QIAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSJjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAC6wAAAUIAAAX4AAADOgAAAuwAAAFhAAAF9wAAAzkAAAAAAAAAAAeAAAAC
7AAAAWEAAAX3AAADOZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwCQ0GUjANBVUOUjANNQUWUjARSTVNFlIwGUmVjYWxs
lIwCUjKUjAlQcmVjaXNpb26UjANNU0WUjAJGMZSMDVRlc3QgdGltZSBbc12UjA5UcmFpbiB0aW1l
IFtzXZSQc4wLX192ZXJzaW9uX1+USwOMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFuZ2V3aWRn
ZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojA9jbGFzc19zZWxlY3Rp
b26UjBYoQXZlcmFnZSBvdmVyIGNsYXNzZXMplEr/////hpSMDGZvbGRfZmVhdHVyZZROSv7///+G
lIwVZm9sZF9mZWF0dXJlX3NlbGVjdGVklIlK/v///4aUaA19lGgcSwN1jAphdHRyaWJ1dGVzlIwB
eJRLAoaUhZSMBW1ldGFzlCmMCmNsYXNzX3ZhcnOUjAF5lEsChpSFlHViaCEpgZR9lChoJH2UKGgm
aCdK/////4aUaCmMCFNlbGVjdGVklEtlhpRoK4lK/v///4aUaA19lGgcSwN1aC5oL0sChpSFlGgy
aDtLAYaUhZRoM2g0SwKGlIWUdWJldS4=
</properties>
		<properties node_id="13" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0', 'scriptLibrary': [{'name': 'Poly_Regression.py', 'script': '# Polynomial Regression\n########################################################\n# Settings:\nname="1"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 1            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - learner and trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}], 'scriptText': '# Polynomial Regression\n########################################################\n# Settings:\nname="Polynomial Regression"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 5            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xbd\x00\x00\x00\xce\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="14" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x00F\x00\x00\x06\x82\x00\x00\x04\x0f\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="15" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x00F\x00\x00\x06\x82\x00\x00\x04\x0f\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="16" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x00x\x00\x00\x00.\x00\x00\x05v\x00\x00\x03\xe0', 'scriptLibrary': [{'name': 'Poly_Regression.py', 'script': '# Polynomial Regression\n########################################################\n# Settings:\nname="1"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 1            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - learner and trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}], 'scriptText': '# Polynomial Regression\n########################################################\n# Settings:\nname="1"         # Name of the learner/model in other widgets, e.g. Test and Score\ndegree = 15            # maximal degree of the polynomial features\nfit_intercept = True  # \ntype = "0"            # 0: ordinary Least square \n                      # 1: Lasso (L1-Regularization)\n                      # 2: Ridge (L2-Regularization)\nalpha = 0.0001        # parameter alpha for L1- and L2-Regularization only\n#################################################################\n# File: Poly_Regression.py\n\n"""\n* Widget input: \n    - (optional) data \n    - (optional) preprocessors on object-input\n\n* Widget output: \n    - learner on learner-output, if no data on input\n    - trained model on classifier-output, if data on input\n\n* Creates a learner for polynomial regression, which can be used e.g. in Test and Score-Widget\n* Additionally creates a trained model, if training data is connectet to data-input, e.g. for Predictions-Widget\n\n"""\n\nimport Orange\ndata = in_data\npreprocessors=in_objects\n\nif type == "0":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LinearRegressionLearner(fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: ordinary Least square")\n\nelif type == "1":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.LassoRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept, max_iter=2000),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Lasso (L1)")\n\nelif type == "2":\n    learner = Orange.regression.linear.PolynomialLearner(\n        learner=Orange.regression.linear.RidgeRegressionLearner(alpha=alpha,  \n            fit_intercept=fit_intercept),\n        degree=degree, preprocessors=preprocessors, include_bias=False)\n    print("\\nAlgorism: Ridge (L2)")\nelse:\n    print("no algorism specified")\n\nlearner.name = name\n\nif data != None:\n    classifier = learner(data)  \n    classifier.name = name\n\nout_learner = learner\nif data != None:\n    out_classifier = classifier \nelse:\n    out_classifier = None\nprint("\\nPreprocessors:")\nprint(preprocessors)\n\n\n# all possible settings for underlying learners for linear regression:\n#Orange.regression.linear.LinearRegressionLearner(preprocessors=None, fit_intercept=True)\n\n#Orange.regression.linear.RidgeRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, copy_X=True, max_iter=None, tol=0.001, solver=\'auto\', preprocessors=None)\n\n#Orange.regression.linear.LassoRegressionLearner(alpha=1.0, fit_intercept=True, normalize=False, precompute=False, copy_X=True, max_iter=1000, tol=0.0001, warm_start=False, positive=False, preprocessors=None)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xbd\x00\x00\x00\xce\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="17" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E', 'scriptLibrary': [{'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 2         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}], 'scriptText': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (mandatory) one prediction (or several predictions) in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\nmeta_columns = in_data.metas.shape[1]\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(meta_columns*len(X_model)).reshape(-1,meta_columns))\n#model_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="18" format="pickle">gASVxQMAAAAAAAB9lCiMFGNvbXBhcmlzb25fY3JpdGVyaW9ulEsAjBJjb250cm9sQXJlYVZpc2li
bGWUiIwNY3Zfc3RyYXRpZmllZJSJjAduX2ZvbGRzlEsCjAluX3JlcGVhdHOUSwOMCnJlc2FtcGxp
bmeUSwCMBHJvcGWURz+5mZmZmZmajAtzYW1wbGVfc2l6ZZRLCYwTc2F2ZWRXaWRnZXRHZW9tZXRy
eZRDQgHZ0MsAAwAAAAAC7AAAAWEAAAX3AAADOQAAAuwAAAFhAAAF9wAAAzkAAAAAAAAAAAeAAAAC
7AAAAWEAAAX3AAADOZSMEnNodWZmbGVfc3RyYXRpZmllZJSIjAh1c2Vfcm9wZZSJjAtzY29yZV90
YWJsZZR9lIwMc2hvd25fc2NvcmVzlI+UKIwCQ0GUjANBVUOUjANNQUWUjARSTVNFlIwGUmVjYWxs
lIwCUjKUjAlQcmVjaXNpb26UjANNU0WUjAJGMZSMDVRlc3QgdGltZSBbc12UjA5UcmFpbiB0aW1l
IFtzXZSQc4wLX192ZXJzaW9uX1+USwOMEGNvbnRleHRfc2V0dGluZ3OUXZQojBVvcmFuZ2V3aWRn
ZXQuc2V0dGluZ3OUjAdDb250ZXh0lJOUKYGUfZQojAZ2YWx1ZXOUfZQojA9jbGFzc19zZWxlY3Rp
b26UjBYoQXZlcmFnZSBvdmVyIGNsYXNzZXMplEr/////hpSMDGZvbGRfZmVhdHVyZZROSv7///+G
lIwVZm9sZF9mZWF0dXJlX3NlbGVjdGVklIlK/v///4aUaA19lGgcSwN1jAphdHRyaWJ1dGVzlIwB
eJRLAoaUhZSMBW1ldGFzlCmMCmNsYXNzX3ZhcnOUjAF5lEsChpSFlHViaCEpgZR9lChoJH2UKIwP
Y2xhc3Nfc2VsZWN0aW9ulIwWKEF2ZXJhZ2Ugb3ZlciBjbGFzc2VzKZRK/////4aUjAxmb2xkX2Zl
YXR1cmWUTkr+////hpSMFWZvbGRfZmVhdHVyZV9zZWxlY3RlZJSJSv7///+GlIwLc2NvcmVfdGFi
bGWUfZRoHEsDdWguKIwCeDCUSwKGlIwEeDBeMpRLAoaUjAR4MF4zlEsChpSMBHgwXjSUSwKGlIwE
eDBeNZRLAoaUdJRoMiloM2g0SwKGlIWUdWJoISmBlH2UKGgkfZQoaDpoO0r/////hpRoPU5K/v//
/4aUaD+JSv7///+GlGhBfZRoHEsDdWgujAJ4MJRLAoaUjAR4MF4ylEsChpSGlGgyKWgzaDRLAoaU
hZR1YmV1Lg==
</properties>
		<properties node_id="19" format="literal">{'auto_commit': True, 'color_by_class': True, 'controlAreaVisible': True, 'dist_color_RGB': (220, 220, 220, 255), 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x03\x10\x00\x00\x00F\x00\x00\x06\x82\x00\x00\x04\x0f\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x03\x11\x00\x00\x00e\x00\x00\x06\x81\x00\x00\x04\x0e', 'select_rows': True, 'selected_cols': [], 'selected_rows': [], 'show_attribute_labels': True, 'show_distributions': False, '__version__': 2}</properties>
		<properties node_id="20" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02\x03\x00\x00\x01=\x00\x00\x06r\x00\x00\x037\x00\x00\x02\x03\x00\x00\x01=\x00\x00\x06r\x00\x00\x037\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02\x03\x00\x00\x01=\x00\x00\x06r\x00\x00\x037', 'scriptLibrary': [{'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-diagram of data\n#################################\n# Settings:\nmetadata = True             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \n    model_name = in_data.domain.metas[prediction_model-1].name\nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n\ndef show(X, y, y_hat, name=model_name):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red", label = "Training data")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(in_data.domain[0])\n        ax.set_ylabel(in_data.domain[1])\n        ax.set_zlabel(in_data.domain.class_var.name)\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue", label = "Model predictions")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue", label = "Model predictions")\n        plt.xlabel(in_data.domain[0])\n        plt.ylabel(in_data.domain.class_var.name)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat, name=model_name)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}], 'scriptText': '# Shows 2D- or 3D-diagram of data\n#################################\n# Settings:\nmetadata = True             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = True          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \n    model_name = in_data.domain.metas[prediction_model-1].name\nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n\ndef show(X, y, y_hat, name=model_name):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red", label = "Training data")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(in_data.domain[0])\n        ax.set_ylabel(in_data.domain[1])\n        ax.set_zlabel(in_data.domain.class_var.name)\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue", label = "Model predictions")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue", label = "Model predictions")\n        plt.xlabel(in_data.domain[0])\n        plt.ylabel(in_data.domain.class_var.name)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat, name=model_name)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01S\x00\x00\x00\x80\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="21" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02\x02\x00\x00\x01\x1e\x00\x00\x06s\x00\x00\x038\x00\x00\x02\x03\x00\x00\x01=\x00\x00\x06r\x00\x00\x037\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02\x03\x00\x00\x01=\x00\x00\x06r\x00\x00\x037', 'scriptLibrary': [{'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-diagram of data\n#################################\n# Settings:\nmetadata = True             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \n    model_name = in_data.domain.metas[prediction_model-1].name\nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n\ndef show(X, y, y_hat, name=model_name):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red", label = "Training data")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(in_data.domain[0])\n        ax.set_ylabel(in_data.domain[1])\n        ax.set_zlabel(in_data.domain.class_var.name)\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue", label = "Model predictions")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue", label = "Model predictions")\n        plt.xlabel(in_data.domain[0])\n        plt.ylabel(in_data.domain.class_var.name)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat, name=model_name)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}], 'scriptText': '# Shows 2D- or 3D-diagram of data\n#################################\n# Settings:\nmetadata = True             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = True          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \n    model_name = in_data.domain.metas[prediction_model-1].name\nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n\ndef show(X, y, y_hat, name=model_name):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red", label = "Training data")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(in_data.domain[0])\n        ax.set_ylabel(in_data.domain[1])\n        ax.set_zlabel(in_data.domain.class_var.name)\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue", label = "Model predictions")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue", label = "Model predictions")\n        plt.xlabel(in_data.domain[0])\n        plt.ylabel(in_data.domain.class_var.name)\n        plt.title(name)\n        plt.legend()\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat, name=model_name)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x01S\x00\x00\x00\x80\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
