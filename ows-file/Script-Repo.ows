<?xml version='1.0' encoding='utf-8'?>
<scheme version="2.0" title="Some Python-Scripts to add fuctionality to Orange-Flows" description="Some Python-Scripts to add fuctionality to Orange-Flows">
	<nodes>
		<node id="0" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="alle Scripte" position="(450, 450)" />
		<node id="1" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Validation_curve.py" position="(150, 150)" />
		<node id="2" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Learning_curve.py" position="(150, 300)" />
		<node id="3" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions.py" position="(300, 150)" />
		<node id="4" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_target_predictions2D.py" position="(300, 300)" />
		<node id="5" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Diagram_partition_boundaries.py" position="(300, 450)" />
		<node id="6" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Plot_Scatter_Matrix.py" position="(150, 450)" />
		<node id="7" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="PolyFeatures.py" position="(450, 150)" />
		<node id="8" name="Python Script" qualified_name="Orange.widgets.data.owpythonscript.OWPythonScript" project_name="Orange3" version="" title="Display_MNIST-Image.py" position="(450, 300)" />
	</nodes>
	<links />
	<annotations>
		<text id="0" type="text/plain" rect="(91.0, 57.0, 418.0, 37.0)" font-family="MS Shell Dlg 2" font-size="16">Some Python-Scripts to add fuctionality to Orange-Flows</text>
	</annotations>
	<thumbnail />
	<node_properties>
		<properties node_id="0" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 9, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x01\xf1\x00\x00\x00V\x00\x00\x06\xc8\x00\x00\x03\xa5\x00\x00\x01\xf2\x00\x00\x00u\x00\x00\x06\xc7\x00\x00\x03\xa4\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x01\xf2\x00\x00\x00u\x00\x00\x06\xc7\x00\x00\x03\xa4', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\n* Widget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\n* Widget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (optional) one prediction in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\n* Widget input: data with (not too many) numerical features\n* Widget output: -\n\nUsage:\n* Show a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\n* Widget input: data (only numerical features are used; categorical features are filtered out)\n* Widget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="1" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 0, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x071\x00\x00\x03\xfe\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x071\x00\x00\x03\xfe\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x071\x00\x00\x03\xfe', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Plot Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Plot Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="2" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 1, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xfe\x00\x00\x03\xb7\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xfe\x00\x00\x03\xb7\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xfe\x00\x00\x03\xb7', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="3" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 3, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb5\x00\x00\x03p\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb5\x00\x00\x03p\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xb5\x00\x00\x03p', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = True             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xd0\x00\x00\x00\x86\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="4" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 4, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x06\xcc\x00\x00\x03E', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (optional) one prediction in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries.py', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and (optional) one prediction in Metas, only numeric values\n  e.g. from test and score widget or from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="5" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 5, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02(\x00\x00\x00i\x00\x00\x05X\x00\x00\x03\x06\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05W\x00\x00\x03\x05\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05W\x00\x00\x03\x05', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="6" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 7, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02(\x00\x00\x00i\x00\x00\x059\x00\x00\x02\xbc\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x058\x00\x00\x02\xbb\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x058\x00\x00\x02\xbb', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\n* Widget input: data with (not too many) numerical features\n* Widget output: -\n\nUsage:\n* Show a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\n* Widget input: data with (not too many) numerical features\n* Widget output: -\n\nUsage:\n* Show a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="7" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 8, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xb0\x00\x00\x03&lt;\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xb0\x00\x00\x03&lt;\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xb0\x00\x00\x03&lt;', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\n* Widget input: data (only numerical features are used; categorical features are filtered out)\n* Widget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\n* Widget input: data (only numerical features are used; categorical features are filtered out)\n* Widget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
		<properties node_id="8" format="literal">{'controlAreaVisible': True, 'currentScriptIndex': 9, 'savedWidgetGeometry': b'\x01\xd9\xd0\xcb\x00\x03\x00\x00\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xf2\x00\x00\x03\x0b\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xf2\x00\x00\x03\x0b\x00\x00\x00\x00\x00\x00\x00\x00\x07\x80\x00\x00\x02)\x00\x00\x00\x88\x00\x00\x05\xf2\x00\x00\x03\x0b', 'scriptLibrary': [{'name': 'Validation_curve.py', 'script': '# Validation Curve\n##################\n# Settings:\nk = 5                       # number of folds\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "R2"                # "R2" or "MSE"; only for regression\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#####################################################\n# File: Validation_curve.py\n\n"""\n* Widget input: data and some learners\n* Widget output: -\n\n* Computes and shows validation curve for connected learners out of cross validation.\n* Uses standard error to indicate variability of the results.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses names of connected learners as x-labels.\n\nUsage: \n* mainly to compare different learner settings for manual hyper parameter optimization.\n* e.g. several learners of the same type, but with different values of a certain hyper parameter\n* Use name in learner widget to indicate different learners\n\n"""\n\nimport numpy as np\nfrom Orange.data import Table\nfrom Orange.evaluation import TestOnTestData\nimport Orange\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearners = in_learners\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nca = np.zeros([len(learners),k])\nmse= np.zeros([len(learners),k])\nr2 = np.zeros([len(learners),k])\nca_train = np.zeros([len(learners),k])\nmse_train = np.zeros([len(learners),k])\nr2_train = np.zeros([len(learners),k])\n\nfor fold in range(k):\n    # Prepairing Folds\n    #-----------------\n    x_train = np.vstack((X[0:fold*int(n/k)], X[(fold+1)*int(n/k):]))\n    if fold==0:\n        y_train = Y[(fold+1)*int(n/k):]\n    else:\n        y_train = np.append(Y[0:fold*int(n/k)], Y[(fold+1)*int(n/k):])\n    x_test  = X[fold*int(n/k): (fold+1)*int(n/k)]\n    y_test  = Y[fold*int(n/k): (fold+1)*int(n/k)]\n\n    trainset = Table.from_numpy(data.domain, X=x_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=x_test, Y=y_test)\n    \n    # Training models on Folds and make predictions\n    #----------------------------------------------\n    models = [learner(trainset) for learner in learners]\n    y_pred_test = [model(testset) for model in models]\n    y_pred_train = [model(trainset) for model in models]\n    \n    # Calculate metrics\n    #------------------\n    if problem == "class":\n        for learner,_ in enumerate(learners):\n            # Metrics see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n            # use only CA to avoid problems with multiclass labels\n            ca[learner, fold] = metrics.accuracy_score(y_test, y_pred_test[learner])\n            ca_train[learner, fold] = metrics.accuracy_score(y_train, y_pred_train[learner])\n            \n    if problem == "reg":\n        for learner,_ in enumerate(learners):\n            # other metrics would be possible; these two should be sufficient\n            mse[learner,fold] = metrics.mean_squared_error(y_test, y_pred_test[learner])\n            r2[learner,fold] = metrics.r2_score(y_test, y_pred_test[learner])\n            mse_train[learner, fold] = metrics.mean_squared_error(y_train, y_pred_train[learner])\n            r2_train[learner, fold] = metrics.r2_score(y_train, y_pred_train[learner])\n\n# Aggregate results (means and standard errors)\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Models"] = [F"{learners[learner]}" for learner,_ in enumerate(learners)]\nif problem == "class":\n    result_table["CA"] = [ca[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se"] = [ca[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["CA_train"] = [ca_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["CA-se_train"] = [ca_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    \nif problem == "reg":\n    result_table["MSE"] = [mse[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se"] = [mse[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2"] = [r2[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se"] = [r2[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["MSE_train"] = [mse_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["MSE-se_train"] = [mse_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n    result_table["R2_train"] = [r2_train[learner].mean() for learner,_ in enumerate(learners)]\n    result_table["R2-se_train"] = [r2_train[learner].std(ddof=1)/k for learner,_ in enumerate(learners)]\n\n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Cross validation")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("Number of folds    : ", k)\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table[["Models", "MSE", "MSE-se", "R2", "R2-se"]])\n    print(result_table[["Models", "MSE_train", "MSE-se_train", "R2_train", "R2-se_train"]])\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n\n# Create Diagram\n#---------------\nfig = plt.figure(figsize=(8,6))\nplt.title("Validation Curve")\nlw = 2\nif problem == "class":\n    plt.ylabel("CA")\n    plt.plot(\n        result_table["Models"].values, result_table["CA_train"].values, label="Training score", color="darkorange", lw=lw\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA_train"].values - result_table["CA-se_train"].values,\n        result_table["CA_train"].values + result_table["CA-se_train"].values,\n        alpha=0.2,\n        color="darkorange",\n        lw=lw,\n    )\n    plt.plot(\n        result_table["Models"].values, result_table["CA"].values, label="Cross-validation score", color="navy"\n    )\n    plt.fill_between(\n        result_table["Models"].values,\n        result_table["CA"].values - result_table["CA-se"].values,\n        result_table["CA"].values + result_table["CA-se"].values,\n        alpha=0.2,\n        color="navy",\n        lw=lw,\n    )\n    plt.legend(loc="best")\n    plt.show()\n    \nif problem == "reg":\n    if score == "MSE":\n        plt.ylabel("MSE")\n        plt.plot(\n            result_table["Models"].values, result_table["MSE_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE_train"].values - result_table["MSE-se_train"].values,\n            result_table["MSE_train"].values + result_table["MSE-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["MSE"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["MSE"].values - result_table["MSE-se"].values,\n            result_table["MSE"].values + result_table["MSE-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n    else:\n        plt.ylabel("R2")\n        plt.plot(\n            result_table["Models"].values, result_table["R2_train"].values, label="Training score", color="darkorange", lw=lw\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2_train"].values - result_table["R2-se_train"].values,\n            result_table["R2_train"].values + result_table["R2-se_train"].values,\n            alpha=0.2,\n            color="darkorange",\n            lw=lw,\n        )\n        plt.plot(\n            result_table["Models"].values, result_table["R2"].values, label="Cross-validation score", color="navy"\n        )\n        plt.fill_between(\n            result_table["Models"].values,\n            result_table["R2"].values - result_table["R2-se"].values,\n            result_table["R2"].values + result_table["R2-se"].values,\n            alpha=0.2,\n            color="navy",\n            lw=lw,\n        )\n        plt.legend(loc="best")\n        plt.show()\n\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Validation_curve.py'}, {'name': 'Learning_curve.py', 'script': '# Plot Learning Curve\n#####################\n# Settings:\nproblem = "reg"             # "class": classification or "reg": Regression\nscore = "RMSE"              # "R2" or "RMSE"; only for regression\nm = 20                      # number different training sizes\nsave_results = False        # True: save Excelfile with results; False: don\'t save\nfile_path = "E:/Downloads/" # file path for save_results\n#                             e.g. "E:/Downloads/" - with slash (!) also in Windows (and trailing slash)\n#############################################################\n# File: Learning_curve.py\n\n"""\n* Widget input: data and one learner\n* Widget output: -\n\n* Computes and shows learning curve for connected (1) learner.\n* Scores are CA (classification accuracy) for classification and R_squared (R2) or RMSE for regression.\n* Uses train-test-split, no cross validation.\n* Can throw an error, if connected learner is not compatible with typ of class variable (numeric or categorical). Just connect a suitable learner.\n\n"""\n\nimport numpy as np\nimport Orange\nfrom Orange.data import Table\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\n\ndata = in_data.copy()\nlearner = in_learner\ndata.shuffle()\nn = len(data)\nX = data.X    # numpy.arrays\nY = data.Y    # numpy.arrays\n\nspacing = np.linspace(5, n, m).round()   # spacing is np.array of floats\ntrain_sizes = [int(i) for i in spacing]  # is list of integers as needed for slicing of y_train\n\n# compute and show learning curve\n#----------------------------------------------\ndef plot_learning_curves(learner, X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n    trainset = Table.from_numpy(data.domain, X=X_train, Y=y_train)\n    testset = Table.from_numpy(data.domain, X=X_test, Y=y_test)\n    train_errors, val_errors = [], []\n    for m in train_sizes:\n        model = learner(trainset[:m])\n        y_pred_test = model(testset)\n        y_pred_train = model(trainset[:m])\n        if problem == "reg":\n            if score == "RMSE":\n                train_errors.append(metrics.mean_squared_error(y_train[:m], y_pred_train, squared=False))\n                val_errors.append(metrics.mean_squared_error(y_test, y_pred_test))\n            if score == "R2":\n                train_errors.append(metrics.r2_score(y_train[:m], y_pred_train))\n                val_errors.append(metrics.r2_score(y_test, y_pred_test))\n        if problem == "class": # CA\n            train_errors.append(metrics.accuracy_score(y_train[:m], y_pred_train))\n            val_errors.append(metrics.accuracy_score(y_test, y_pred_test))\n    \n    plt.plot(train_sizes, train_errors, "r-o", linewidth=2, label="train")\n    plt.plot(train_sizes, val_errors, "b-", linewidth=3, label="test")\n    plt.title("Learning Curve")\n    if problem == "reg" and score == "RMSE": plt.ylabel("RMSE")\n    if problem == "reg" and score == "R2": plt.ylabel("R2")\n    if problem == "class": plt.ylabel("CA")\n    plt.xlabel("Number of training samples")\n    plt.legend(loc="best")\n    plt.show()\n    return train_errors, val_errors\n\ntrain_errors, val_errors = plot_learning_curves(learner, X, Y)\n\n# aggregate results\n#----------------------------------------------\nresult_table = pd.DataFrame([])\nresult_table["Train sizes"] = train_sizes\nif problem == "class":\n    result_table["CA_train"] = train_errors\n    result_table["CA_test"] = val_errors\nif problem == "reg" and score == "RMSE":\n    result_table["RMSE_train"] = train_errors\n    result_table["RMSE_test"] = val_errors\nif problem == "reg" and score == "R2":\n    result_table["R2_train"] = train_errors\n    result_table["R2_test"] = val_errors\n    \n# Print to table and save data\n#-----------------------------\nprint("---------------------------")\nprint("Results of Learning Curve")\nprint("---------------------------")\nprint("Number of instances: ", len(data))\nprint("")\nif problem == "class":\n    print(result_table)\nif problem == "reg":\n    print(result_table)\n\nif save_results:\n    file_name_path = file_path + "Results-" + datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + ".xlsx"\n    print("Results in: ",file_name_path)\n    with pd.ExcelWriter(file_name_path) as writer:\n        result_table.to_excel(writer)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Learning_curve.py'}, {'name': '-----', 'script': '', 'filename': None}, {'name': 'Diagram_target_predictions.py', 'script': '# Shows 2D- or 3D-doagram of data\n#################################\n# Settings:\nmetadata = False             # False  if metadata/predictions should not be shown\n#                             True   if metadata/predictions should be shown\nenforce_2D = False          # True   if 2D-diagram should be shown, although \n#                             two dimensions (features) are available in input data\nscatter_prediction = True   # True -&gt; dots, False -&gt; lines for metadata/predictions \n#                             in 2D-diagram\nprediction_model = 1        # Standard 1 for 1 column of predictions in metadata or\n#                             first column of predictions; \n#                             otherwise number of column, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions.py\n\n"""\nWidget input: data with one or two numerical features, numerial target and (optional) one or several predictions, stored as metadata\nWidget output: -\n\nUsage:\n* Show numerical data with target and one feature in a scatterplot together with predicted data\n* Show numerical data with target and two features in a 3D-scatterplot together with predicted data\n* Predictions can be shown as dots or as line in 2D- and as surface in 3D-plots.\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n#x1 = in_data.X[:,0]\n#x2 = in_data.X[:,1]\nX = in_data.X\ny = in_data.Y\nif metadata: \n    y_hat = in_data.metas[:,prediction_model-1] \nelse: y_hat=None\n\nif X.shape[1] ==2: display_3D = True \nelse: display_3D = False\n\nif enforce_2D: display_3D = False\n    \ndef show(X, y, y_hat):\n    if display_3D:\n        fig = plt.figure()\n        ax = fig.add_subplot(111, projection=\'3d\')\n        ax.scatter(X[:,0], X[:,1], y, s= 10, marker="o", c="red")\n        if metadata: ax.plot_trisurf(X[:,0], X[:,1], y_hat, alpha=0.5)\n        ax.set_xlabel(\'x1\')\n        ax.set_ylabel(\'x2\')\n        ax.set_zlabel(\'y\')\n        ax.set_xlim(0, X[:,0].max()+2)\n        ax.set_ylim(0, X[:,1].max()+2)\n        #ax.set_zlim(0, 400)\n        plt.show()\n    else:\n        fig = plt.figure()\n        ax = fig.add_subplot(111)\n        ax.scatter(X[:,0], y, marker="o", c="red")\n        if metadata:\n            if scatter_prediction:\n                ax.scatter(X[:,0], y_hat, marker="+", c="blue")\n            else:\n                ax.plot(X[:,0], y_hat,  c="blue")\n        plt.show()\n\nshow(X=X, y=y, y_hat=y_hat)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions.py'}, {'name': '2D-Diagram_target_predictions2D.py', 'script': '# Shows 2D-diagram with training data and predictions out of connected model\n######################################################\n# Settings:\nprediction_model = 1         # Standard 1 for 1 connected model or the first connected model; \n#                              otherwise number of model, whose predictions should be shown\n#####################################################\n# File: Diagram_target_predictions2D.py\n\n"""\n* Widget input: \n- data with one feature, one target and one prediction in Metas, only numeric values\n  e.g. from test and score widget of from predictions widget)\n- trained model (or several trained models) on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show prediction performance and over-/underfitting\n\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nX = in_data.X\ny = in_data.Y\nmodels = in_classifiers\n#print(models)\n\nx_min = X[:,0].min()\nx_max = X[:,0].max()\nX_model = np.linspace(x_min, x_max, 500)\n\nmodel_data = Orange.data.Table.from_numpy(in_data.domain, X_model.reshape(-1,1), Y = np.zeros(len(X_model)), metas = np.zeros(len(X_model)).reshape(-1,1))\n\ny_hat = []\nfor model in models:\n    y_hat.append(model(model_data))\n    print(model.name)\n\ndef show(X, y, y_hat, name):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    ax.scatter(X[:,0], y, marker="o", c="red", label = "Training data")\n    ax.plot(X_model, y_hat,  c="blue", label = "Model predictions")\n    plt.title("Model: " + name)\n    plt.xlabel(in_data.domain[0])\n    plt.ylabel(in_data.domain[1])\n    plt.legend()\n    plt.show()\n\nshow(X=X, y=y, y_hat=y_hat[prediction_model-1], name=models[prediction_model-1].name)\n\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Diagram_target_predictions2D.py'}, {'name': 'Diagram_partition_boundaries', 'script': '# Shows 2D-diagram of data with partition boundaries\n####################################################\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': '-----', 'script': '# Shows 2D-diagram of data with partition boundaries\n# (no settings)\n#####################################################\n# File: Diagram_partition_boundaries.py\n\n"""\n* Widget input: \n- data with two numerical features, one categorical target\n- trained model on classifier input\n\n* Widget output: -\n\nUsage:\n* to visually show partition boundaries and over-/underfitting\n\n\nadapted from:\nPython Data Science Handbook – Essential Tools for Working with Data\nISBN 978-1491912058, 2017, from Jake VanderPlas\n"""\n\nimport Orange\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndata = in_data\nmodel = in_classifier\n\ndef visualize_classifier(model, data, ax=None, cmap=\'rainbow\'):\n    X = data.X\n    y = data.Y\n    ax = ax or plt.gca()\n    # show training data\n    ax.scatter(X[:, 0], X[:, 1], c=y, s=100, cmap=cmap, clim=(y.min(), y.max()), zorder=3)\n    xlim = ax.get_xlim()\n    ylim = ax.get_ylim()\n\n    # create grid and compute predictions on grid data\n    xx, yy = np.meshgrid(np.linspace(*xlim, num=200), np.linspace(*ylim, num=200))\n    Z = model((np.c_[xx.ravel(), yy.ravel()])).reshape(xx.shape)\n\n    # create diagram of grid data\n    n_classes = len(np.unique(y))\n    ax.scatter(xx,yy,Z)\n    contours = ax.contourf(xx, yy, Z, alpha=0.3, levels=np.arange(n_classes + 1) - 0.5, cmap=cmap,  zorder=1)\n    ax.set(xlim=xlim, ylim=ylim)\n    plt.show()\n    \nvisualize_classifier(model=model, data=data)\n', 'filename': None}, {'name': 'Plot_Scatter_Matrix.py', 'script': '# Creates a scatter matrix plot of features\n###########################################\n# no settings\n#####################################################\n# File: Plot_Scatter_Matrix.py\n"""\nWidget input: data with (not too many) numerical features\nWidget output: -\n\nUsage:\nShow a scatter matrix plot to see distribution and correlation of features\n\n"""\n\nfrom Orange.data.pandas_compat import table_from_frame,table_to_frame\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ndf= table_to_frame(in_data)\npd.plotting.scatter_matrix(df, alpha=0.5, diagonal = \'hist\')\nplt.suptitle(\'Scatter Matrix\')\nplt.show()\n\n# possible alternativ in pd.plotting.scatter_matrix\n# diagonal = \'kde\'    : core density estimation in diagonal\n# diagonal = \'hist\'   : histogram in diaagonal', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Plot_Scatter_Matrix.py'}, {'name': 'PolyFeatures.py', 'script': '# Generate polynomial and interaction features from input data\n########################################################\n# Settings:\ndegree = 2     # maximal degree of the polynomial features\n#################################################################\n# File: PolyFeatures.py\n\n"""\nWidget input: data (only numerical features are used; categorical features are filtered out)\nWidget output: data with additinal features, generated as polynomial combinations of the features\n\nUsage:\n* Create additional features to use linear regression for modeling nonlinear functions\n* Use to show the effect of model complexity on overfitting the data\n\n"""\n\n\nimport Orange\nfrom Orange.data import Domain, Table\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# use only numerical features, leave out other features:\ndomain = Domain([attr for attr in in_data.domain.attributes\n                 if attr.is_continuous], in_data.domain.class_vars)\nfiltered_data = Table.from_table(domain, in_data)\nX=filtered_data.X\n\n# generate new features with sklearn.preprocessing.PolynomialFeatures\npoly_features = PolynomialFeatures(degree=degree, include_bias=False)\nX_engi = poly_features.fit_transform(X)\n\n# create new domain and column-headers out of the feature_names, which are created by PolynomialFeatures\nattr_list = []\nfor i in range(len(poly_features.get_feature_names())):\n  attr1 = Orange.data.ContinuousVariable(poly_features.get_feature_names()[i])\n  attr_list.append(attr1)\n#  print(i)\n#  print(attr1.name)\nengi_domain = Domain(attr_list, in_data.domain.class_vars)\n\nout_data = Orange.data.Table(engi_domain, X_engi, in_data.Y)\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/PolyFeatures.py'}, {'name': 'Display_MNIST-Image.py', 'script': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'filename': 'C:/Users/00613/Sync-Austausch/_ML/_Orange/Orange-Python-Scripts/Display_MNIST-Image.py'}], 'scriptText': '# Shows one instance of MNIST-data as image\n###########################################\n# no settings\n################################\n# File: Display_MNIST-Image.py\n\n"""\n* Widget input: data with (only) one instance of MNIST-data\n* Widget output: -\n\nUsage:\nTo visualize example data from MNIST (handwritten numbers)\n* X-data should be in 784 features representing the pixels in the 28x28 matrix.\n* Use Data Table Widget so select one row (and for example Confusion Matrix Widget in front of Data Table to select a group of instances).\n\n"""\n\n\nimport Orange\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nsome_digit = in_data.X\nsome_digit_image = some_digit.reshape(28, 28)\n\nplt.imshow(some_digit_image, cmap="binary")\nplt.axis("off")\nplt.show()\n', 'splitterState': b'\x00\x00\x00\xff\x00\x00\x00\x01\x00\x00\x00\x02\x00\x00\x02\xe0\x00\x00\x01i\x01\xff\xff\xff\xff\x01\x00\x00\x00\x02\x00', 'vimModeEnabled': False, '__version__': 2}</properties>
	</node_properties>
	<session_state>
		<window_groups />
	</session_state>
</scheme>
